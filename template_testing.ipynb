{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENCIES\n",
    "import glob\n",
    "#from shutil import copyfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import logomaker\n",
    "# LOCAL IMPORTS\n",
    "#from indexing_classes import GPCRDBIndexing\n",
    "import sse_func\n",
    "import matplotlib.pyplot as plt\n",
    "import template_finder as tf\n",
    "\n",
    "def calc_identity(aln_matrix, return_best_aa=False):\n",
    "    # This takes an alignment matrix with shape=(n_columns, n_sequences) and generates counts based on the identity matrix.\n",
    "    # Returns the highest non \"-\" residue count as the most conserved residue and its occupancy based on count(\"-\") - n_struc\n",
    "    n_struc = aln_matrix.shape[0]\n",
    "    quality = []\n",
    "    occ = []\n",
    "    aa = []\n",
    "    for col in range(aln_matrix.shape[1]):\n",
    "        chars, count = np.unique(aln_matrix[:,col], return_counts=True)\n",
    "        dtype = [('aa', 'S1'), ('counts', int)]\n",
    "        values = np.array(list(zip(chars,count)), dtype=dtype)\n",
    "        s_values = np.sort(values, order='counts')\n",
    "\n",
    "        if s_values[-1][0] == b'-':\n",
    "            q = s_values[-2][1]\n",
    "            aa.append(s_values[-2][0])\n",
    "        else:\n",
    "            q = s_values[-1][1]\n",
    "            aa.append(s_values[-1][0])\n",
    "        x = np.where(chars == '-')[0][0]\n",
    "        occ.append(n_struc - count[x])\n",
    "        quality.append(q)\n",
    "    if not return_best_aa:\n",
    "        return quality, occ\n",
    "    if return_best_aa:\n",
    "        return quality, occ, aa\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the valid GAIN domain Dataset and specify the pdb path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14435\n"
     ]
    }
   ],
   "source": [
    "# In addition to the collection, we need the corresponding PDB files.\n",
    "valid_collection = pd.read_pickle(\"../valid_collection.pkl\")\n",
    "allpdbs = '../all_pdbs/*.pdb'\n",
    "print(len(valid_collection.collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Data for the initially selected templates\n",
    "def get_gain(identifier, a_gain_collection):\n",
    "    for gain in a_gain_collection:\n",
    "        if identifier in gain.name:\n",
    "            return gain\n",
    "        \n",
    "def get_struc_aln_anchors(gain, aln_dict, subdomain='a', threshold=3):\n",
    "    aln_matrix = np.array([list(seq) for seq in aln_dict.values()])\n",
    "    # Get the identity scores from the alignment\n",
    "    quality, occ, aa = calc_identity(aln_matrix, return_best_aa=True)\n",
    "    # The columns here exactly correspond to the template sequence order\n",
    "    if subdomain.lower() == 'a':\n",
    "        sse = gain.sda_helices\n",
    "        d_string = \"HELIX \"\n",
    "        sse_type = \"H\"\n",
    "    elif subdomain.lower() == 'b':\n",
    "        sse = gain.sdb_sheets\n",
    "        d_string = \"STRAND\"\n",
    "        sse_type = \"S\"\n",
    "    else:\n",
    "        print(\"NO SUBDOMAIN specified. EXITING.\")\n",
    "    \n",
    "    anchor_quality = {}\n",
    "    anchors = {}\n",
    "    counter = 1\n",
    "\n",
    "    for i,element in enumerate(sse):\n",
    "        if element[1]-element[0] <= threshold:\n",
    "            print(\"Element length below threshold. Skipping.\", element)\n",
    "            continue\n",
    "        if subdomain =='a' and gain.start+element[0] > gain.subdomain_boundary:\n",
    "            print(\"Skipping Subdomain A Helix\", element)\n",
    "            continue\n",
    "\n",
    "        q = quality[element[0]:element[1]+1]\n",
    "        label = f'{sse_type}{counter}'\n",
    "        max_id = element[0]+np.argmax(q)+1\n",
    "        max_res = gain.sequence[max_id]\n",
    "\n",
    "        res_id = gain.start+max_id+1\n",
    "\n",
    "        print(f\"{d_string} #{i+1}: {max_res}{res_id} @ SSE residue {max_id-element[0]} | q = {np.max(q)} with res_idx {max_id} | MOST CONSERVED: {aa[max_id]} | PDB-res {gain.start+element[0]+1}-{gain.start+element[1]+1}\")\n",
    "        anchor_quality[label] = np.max(q)\n",
    "        anchors[label] = max_id\n",
    "        counter += 1\n",
    "        pdb_anchors = {v:k+gain.start+1 for v,k in anchors.items()}\n",
    "    print(\"__________\")\n",
    "    return anchors, anchor_quality, pdb_anchors\n",
    "\n",
    "def get_template_information(identifier, gain_collection, subdomain='a', threshold=3, no_input=True):\n",
    "    for gain in gain_collection.collection:\n",
    "        if identifier in gain.name:\n",
    "            print(gain.name, gain.start, gain.subdomain_boundary, gain.end, \"\\n\")\n",
    "\n",
    "            if subdomain.lower() == 'a':\n",
    "                sse = gain.sda_helices\n",
    "                d_string = \"HELIX \"\n",
    "                sse_type = \"H\"\n",
    "            elif subdomain.lower() == 'b':\n",
    "                sse = gain.sdb_sheets\n",
    "                d_string = \"STRAND\"\n",
    "                sse_type = \"S\"\n",
    "            else:\n",
    "                print(\"NO SUBDOMAIN specified. EXITING.\")\n",
    "        \n",
    "            #print(sse)\n",
    "            anchor_quality = {}\n",
    "            anchors = {}\n",
    "            counter = 1\n",
    "            aln_indices = []\n",
    "            for i,element in enumerate(sse):\n",
    "                if element[1]-element[0] <= threshold:\n",
    "                    print(\"Element length below threshold. Skipping.\", element)\n",
    "                    continue\n",
    "                if subdomain =='a' and gain.start+element[0] > gain.subdomain_boundary:\n",
    "                    print(\"Skipping Subdomain A Helix\", element)\n",
    "                    continue\n",
    "                label = f'{sse_type}{counter}'\n",
    "                q = [ gain.residue_quality[res] for res in range(element[0], element[1]+1)]\n",
    "                max_id = element[0]+np.argmax(q)\n",
    "                max_res = gain.sequence[max_id]\n",
    "                #aln_idx = gain.alignment_indices[max_id]\n",
    "                res_id = gain.start+max_id+1\n",
    "                print(f\"{d_string} #{i+1}: {max_res}{res_id} @ SSE residue {max_id-element[0]} | q = {np.max(q)} with res_idx {max_id} | {q} | {gain.start+element[0]}-{gain.start+element[1]}\")\n",
    "                if not no_input:\n",
    "                    confirm = input(f\"{d_string} #{i+1}: {max_res}{res_id} @ SSE re {max_id-element[0]} | q={np.max(q)} w res_idx {max_id} | {gain.start+element[0]}-{gain.start+element[1]}. Keep?\")\n",
    "                    if confirm.lower() != \"y\":\n",
    "                        print(\"Skipping this anchor.\");continue\n",
    "                anchor_quality[label] = np.max(q)\n",
    "                anchors[label] = max_id\n",
    "                aln_indices.append(gain.alignment_indices[max_id])\n",
    "                counter += 1\n",
    "            pdb_anchors = {v:k+gain.start+1 for v,k in anchors.items()}\n",
    "            print(\"__________\")\n",
    "            return anchors, anchor_quality, aln_indices, pdb_anchors\n",
    "\n",
    "# Test:\n",
    "# _,_,_,_ = get_template_information('A0A6G1Q0B9', valid_collection, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../r2_template_pdbs/G5b_A0A6J3IBI5.pdb\n",
      "Created ../G5b_A0A6J3IBI5_sdb\n",
      "Written a total of 14435 GESAMT commands to file.\n",
      "Running set of GESAMT comparisons with 6 threads.\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"    tf.run_gesamt_execution(valid_collection.collection, \\n                            outfolder=gesamt_outfolder, \\n                            pdb_folder='../all_pdbs', \\n                            domain='sda', \\n                            n_threads=6, \\n                            max_struc=len(valid_collection.collection), \\n                            no_run=False,\\n                            template=current_template)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a GESAMT bashfile for pairwise aln to each subdomain. Output the resulting PDB into respective folder\n",
    "#SDB TEMPLATE\n",
    "\n",
    "sdb_r1_template = {'E5b':'A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula'}\n",
    "sdb_templates = {'E5b':'A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula',\n",
    "                 #'G1b':'A0A7L3GD10-A0A7L3GD10_9AVES-AGRG1-Anhinga_rufa', \n",
    "                 #'G3b':'A0A3Q7QGV6-A0A3Q7QGV6_CALUR-AGRG3-likeisoformX3-Callorhinus_ursinus',\n",
    "                 'G5b':'A0A6J3IBI5-A0A6J3IBI5_SAPAP-AGRG5-Sapajus_apella'}\n",
    "# SDA TEMPLATEs\n",
    "sda_r1_templates = {'A': 'A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus', \n",
    "                    'B': 'A0A4W6DVA0-A0A4W6DVA0_LATCA-AGRB1b-Lates_calcarifer', \n",
    "                    'C': 'A0A7K6E127-A0A7K6E127_9PASS-CELR3protein-Grantiella_picta.', \n",
    "                    'D': 'A0A1A7WJQ6-A0A1A7WJQ6_9TELE-GR144-Iconisemion_striatum.', \n",
    "                    'E': 'A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula', \n",
    "                    'F': 'A0A452IH20-A0A452IH20_9SAUR-AGRF5-Gopherus_agassizii', \n",
    "                    'G': 'A0A1W4WJB1-A0A1W4WJB1_AGRPL-AGRG6-likeisoformX1-Agrilus_planipennis', \n",
    "                    'L': 'A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii', \n",
    "                    'V': 'A0A6Q2XYK2-A0A6Q2XYK2_ESOLU-AGRV1-Esox_lucius',\n",
    "                    'X': \"A0A6F9A857-A0A6F9A857_9TELE-Uncharacterizedprotein-Coregonus_sp._'balchen'.\"}\n",
    "\n",
    "sda_r2_templates = {'G1': 'A0A7L3GD10-A0A7L3GD10_9AVES-AGRG1-Anhinga_rufa', \n",
    "                    'G2': 'A0A2K5MG19-A0A2K5MG19_CERAT-AGRG2-Cercocebus_atys', \n",
    "                    'G3': 'A0A3Q7QGV6-A0A3Q7QGV6_CALUR-AGRG3-likeisoformX3-Callorhinus_ursinus', \n",
    "                    'G4': 'A0A2I4CCH8-A0A2I4CCH8_9TELE-AGRG4-like-Austrofundulus_limnaeus.', \n",
    "                    'G5': 'A0A6J3IBI5-A0A6J3IBI5_SAPAP-AGRG5-Sapajus_apella', \n",
    "                    'G6': 'A0A6P7HB06-A0A6P7HB06_9TELE-AGRG6isoformX6-Parambassis_ranga', \n",
    "                    #'G6.1': 'F6QI92-F6QI92_CALJA-AGRG6-Callithrix_jacchus', \n",
    "                    #'G6.2':'A0A7J7WUN2-A0A7J7WUN2_MYOMY-AGRG6-Myotis_myotis',\n",
    "                    'G7': 'A0A2K5Y1I7-A0A2K5Y1I7_MANLE-AGRG7-Mandrillus_leucophaeus', \n",
    "                    'E1': 'A0A2I2YJG7-A0A2I2YJG7_GORGO-AGRE1-Gorilla_gorilla_gorilla', \n",
    "                    'E2': 'A0A2Y9QG39-A0A2Y9QG39_TRIMA-AGRE2isoformX3-Trichechus_manatus_latirostris', \n",
    "                    'E3': 'A0A2Y9M464-A0A2Y9M464_DELLE-AGRE3isoformX1-Delphinapterus_leucas', \n",
    "                    'E4': 'A0A6J3FRL0-A0A6J3FRL0_SAPAP-putativeAGRE4PisoformX1-Sapajus_apella', \n",
    "                    'E5': 'G1TKX5-G1TKX5_RABIT-AGRE5-Oryctolagus_cuniculus', \n",
    "                    #'E5.1': 'A0A2R9CT02-A0A2R9CT02_PANPA-AGRE5-Pan_paniscus',\n",
    "                    #'E5.2': 'F6PLI2-F6PLI2_CANLF-AGRE5-Canis_lupus_familiaris',\n",
    "                    'F2': 'A0A452SUX4-A0A452SUX4_URSAM-AGRF2-Ursus_americanus', \n",
    "                    #'F2.1':'A0A3Q0CU45-A0A3Q0CU45_MESAU-AGRF2-Mesocricetus_auratus',  \n",
    "                    #'F2.2':'E2RAG2-E2RAG2_CANLF-AGRF2-Canis_lupus_familiaris',\n",
    "                    'F4': 'W5PQ70-W5PQ70_SHEEP-AGRF4-Ovis_aries', \n",
    "                    'F5': 'A0A7L3N0A5-A0A7L3N0A5_9AVES-AGRF5protein-Oreotrochilus_melanogaster.', \n",
    "                    #'F5.1':'A0A1U7SCS2-A0A1U7SCS2_ALLSI-AGRF5isoformX1-Alligator_sinensis',\n",
    "                    #'F5.2':'A0A7K5GSD3-A0A7K5GSD3_9AVES-AGRF5protein-Chunga_burmeisteri',\n",
    "                    'D1': 'A0A369SLT5-A0A369SLT5_9METZ-AGRD1-Trichoplax_sp._H2.', \n",
    "                    'L4': 'A0A7L3KTA8-A0A7L3KTA8_9PASS-AGRL4protein-Drymodes_brunneopygia.'}\n",
    "\n",
    "sda_templates = {\n",
    "    'A': 'A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus',\n",
    "    'C': 'A0A7K6E127-A0A7K6E127_9PASS-CELR3protein-Grantiella_picta.', \n",
    "    'D': 'A0A1A7WJQ6-A0A1A7WJQ6_9TELE-GR144-Iconisemion_striatum.', \n",
    "    'E1': 'A0A2I2YJG7-A0A2I2YJG7_GORGO-AGRE1-Gorilla_gorilla_gorilla', \n",
    "    'E5': 'G1TKX5-G1TKX5_RABIT-AGRE5-Oryctolagus_cuniculus', \n",
    "    'F5': 'A0A7L3N0A5-A0A7L3N0A5_9AVES-AGRF5protein-Oreotrochilus_melanogaster.',\n",
    "    'F4': 'W5PQ70-W5PQ70_SHEEP-AGRF4-Ovis_aries', \n",
    "    'G7': 'A0A2K5Y1I7-A0A2K5Y1I7_MANLE-AGRG7-Mandrillus_leucophaeus', \n",
    "    'L': 'A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii', \n",
    "    'L4': 'A0A7L3KTA8-A0A7L3KTA8_9PASS-AGRL4protein-Drymodes_brunneopygia.',\n",
    "    'V': 'A0A6Q2XYK2-A0A6Q2XYK2_ESOLU-AGRV1-Esox_lucius'\n",
    "}\n",
    "\n",
    "def find_pdb(name, pdb_folder):\n",
    "    identifier = name.split(\"-\")[0]\n",
    "    target_pdb = glob.glob(f\"{pdb_folder}/*{identifier}*.pdb\")[0]\n",
    "    return target_pdb\n",
    "\n",
    "#for t_name, sdb_template in sdb_r1_template.items():\n",
    "for i in range(1):\n",
    "    t_name, sdb_template = 'G5b','A0A6J3IBI5-A0A6J3IBI5_SAPAP-AGRG5-Sapajus_apella'\n",
    "    sdb_template_pdb = find_pdb(sdb_template, '../r2_template_pdbs')#'../r2_sdb_templates')\n",
    "    print(sdb_template_pdb)\n",
    "    tf.run_gesamt_execution(valid_collection.collection, \n",
    "                                outfolder=f\"../{t_name}_{sdb_template.split('-')[0]}_sdb\",\n",
    "                                pdb_folder='../all_pdbs', \n",
    "                                domain='sdb', \n",
    "                                n_threads=6, \n",
    "                                max_struc=len(valid_collection.collection), \n",
    "                                no_run=False,\n",
    "                                template=sdb_template_pdb)\n",
    "\n",
    "for fam, prot in sda_templates.items():\n",
    "    identifier = prot.split(\"-\")[0]\n",
    "    current_template = find_pdb(prot, '../r2_template_pdbs')\n",
    "\n",
    "    gesamt_outfolder = f'../{fam}_{identifier}_sda'\n",
    "\n",
    "\"\"\"    tf.run_gesamt_execution(valid_collection.collection, \n",
    "                            outfolder=gesamt_outfolder, \n",
    "                            pdb_folder='../all_pdbs', \n",
    "                            domain='sda', \n",
    "                            n_threads=6, \n",
    "                            max_struc=len(valid_collection.collection), \n",
    "                            no_run=False,\n",
    "                            template=current_template)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused SDA and SDB templates into a single dictionary: {'E5b': ['A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula', 'b', '../E5b_A0A3P8S994_sdb'], 'G5b': ['A0A6J3IBI5-A0A6J3IBI5_SAPAP-AGRG5-Sapajus_apella', 'b', '../G5b_A0A6J3IBI5_sdb'], 'A': ['A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus', 'a', '../A_A0A2Y9F628_sda'], 'C': ['A0A7K6E127-A0A7K6E127_9PASS-CELR3protein-Grantiella_picta.', 'a', '../C_A0A7K6E127_sda'], 'D': ['A0A1A7WJQ6-A0A1A7WJQ6_9TELE-GR144-Iconisemion_striatum.', 'a', '../D_A0A1A7WJQ6_sda'], 'E1': ['A0A2I2YJG7-A0A2I2YJG7_GORGO-AGRE1-Gorilla_gorilla_gorilla', 'a', '../E1_A0A2I2YJG7_sda'], 'E5': ['G1TKX5-G1TKX5_RABIT-AGRE5-Oryctolagus_cuniculus', 'a', '../E5_G1TKX5_sda'], 'F5': ['A0A7L3N0A5-A0A7L3N0A5_9AVES-AGRF5protein-Oreotrochilus_melanogaster.', 'a', '../F5_A0A7L3N0A5_sda'], 'F4': ['W5PQ70-W5PQ70_SHEEP-AGRF4-Ovis_aries', 'a', '../F4_W5PQ70_sda'], 'G7': ['A0A2K5Y1I7-A0A2K5Y1I7_MANLE-AGRG7-Mandrillus_leucophaeus', 'a', '../G7_A0A2K5Y1I7_sda'], 'L': ['A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii', 'a', '../L_A0A452HCU9_sda'], 'L4': ['A0A7L3KTA8-A0A7L3KTA8_9PASS-AGRL4protein-Drymodes_brunneopygia.', 'a', '../L4_A0A7L3KTA8_sda'], 'V': ['A0A6Q2XYK2-A0A6Q2XYK2_ESOLU-AGRV1-Esox_lucius', 'a', '../V_A0A6Q2XYK2_sda']}\n",
      "[NOTE]: GESAMT Alignment has failed. Skipping: gain.name = 'A0A2I3LD70-A0A2I3LD70_PAPAN-AGRE2-Papio_anubis' with \n",
      "\tgain.sda_helices =array([[  5,  35],\n",
      "       [ 38,  61],\n",
      "       [ 67, 102],\n",
      "       [109, 140]])\n",
      "\tgain.sdb_sheets = array([[142, 143],\n",
      "       [146, 149]])\n",
      "[NOTE]: ../A0A3P8S994_E5b.struc_aln.fa overwritten.\n",
      "STRAND #1: T325 @ SSE residue 1 | q = 4001 with res_idx 99 | MOST CONSERVED: b'V' | PDB-res 324-328\n",
      "STRAND #2: V334 @ SSE residue 2 | q = 8422 with res_idx 108 | MOST CONSERVED: b'L' | PDB-res 332-340\n",
      "STRAND #3: L351 @ SSE residue 3 | q = 6986 with res_idx 125 | MOST CONSERVED: b'F' | PDB-res 348-353\n",
      "STRAND #4: T360 @ SSE residue 4 | q = 8568 with res_idx 134 | MOST CONSERVED: b'L' | PDB-res 356-361\n",
      "STRAND #5: Y382 @ SSE residue 8 | q = 8401 with res_idx 156 | MOST CONSERVED: b'Y' | PDB-res 374-382\n",
      "STRAND #6: V410 @ SSE residue 3 | q = 8083 with res_idx 184 | MOST CONSERVED: b'V' | PDB-res 407-410\n",
      "STRAND #7: V414 @ SSE residue 0 | q = 10821 with res_idx 188 | MOST CONSERVED: b'V' | PDB-res 414-419\n",
      "STRAND #8: V431 @ SSE residue 0 | q = 9351 with res_idx 205 | MOST CONSERVED: b'V' | PDB-res 431-436\n",
      "STRAND #9: W454 @ SSE residue 7 | q = 13107 with res_idx 228 | MOST CONSERVED: b'W' | PDB-res 447-455\n",
      "STRAND #10: W460 @ SSE residue 1 | q = 14117 with res_idx 234 | MOST CONSERVED: b'W' | PDB-res 459-461\n",
      "STRAND #11: C465 @ SSE residue 0 | q = 14114 with res_idx 239 | MOST CONSERVED: b'C' | PDB-res 465-470\n",
      "STRAND #12: C479 @ SSE residue 5 | q = 13828 with res_idx 253 | MOST CONSERVED: b'C' | PDB-res 474-479\n",
      "STRAND #13: L488 @ SSE residue 4 | q = 13571 with res_idx 262 | MOST CONSERVED: b'L' | PDB-res 484-491\n",
      "__________\n",
      "{'S1': 99, 'S2': 108, 'S3': 125, 'S4': 134, 'S5': 156, 'S6': 184, 'S7': 188, 'S8': 205, 'S9': 228, 'S10': 234, 'S11': 239, 'S12': 253, 'S13': 262} {'S1': 4001, 'S2': 8422, 'S3': 6986, 'S4': 8568, 'S5': 8401, 'S6': 8083, 'S7': 10821, 'S8': 9351, 'S9': 13107, 'S10': 14117, 'S11': 14114, 'S12': 13828, 'S13': 13571} {'S1': 325, 'S2': 334, 'S3': 351, 'S4': 360, 'S5': 382, 'S6': 410, 'S7': 414, 'S8': 431, 'S9': 454, 'S10': 460, 'S11': 465, 'S12': 479, 'S13': 488}\n",
      "[NOTE]: GESAMT Alignment has failed. Skipping: gain.name = 'A0A2I3LD70-A0A2I3LD70_PAPAN-AGRE2-Papio_anubis' with \n",
      "\tgain.sda_helices =array([[  5,  35],\n",
      "       [ 38,  61],\n",
      "       [ 67, 102],\n",
      "       [109, 140]])\n",
      "\tgain.sdb_sheets = array([[142, 143],\n",
      "       [146, 149]])\n",
      "[NOTE]: ../A0A6J3IBI5_G5b.struc_aln.fa overwritten.\n",
      "STRAND #1: T66 @ SSE residue 1 | q = 4022 with res_idx 65 | MOST CONSERVED: b'V' | PDB-res 65-69\n",
      "STRAND #2: L75 @ SSE residue 2 | q = 8419 with res_idx 74 | MOST CONSERVED: b'L' | PDB-res 73-80\n",
      "STRAND #3: T89 @ SSE residue 2 | q = 7880 with res_idx 88 | MOST CONSERVED: b'F' | PDB-res 87-90\n",
      "STRAND #4: P108 @ SSE residue 4 | q = 8573 with res_idx 107 | MOST CONSERVED: b'L' | PDB-res 104-108\n",
      "STRAND #5: S131 @ SSE residue 7 | q = 8399 with res_idx 130 | MOST CONSERVED: b'Y' | PDB-res 124-131\n",
      "STRAND #6: L150 @ SSE residue 6 | q = 10820 with res_idx 149 | MOST CONSERVED: b'V' | PDB-res 144-155\n",
      "STRAND #7: N167 @ SSE residue 0 | q = 9341 with res_idx 166 | MOST CONSERVED: b'V' | PDB-res 167-172\n",
      "STRAND #8: K187 @ SSE residue 7 | q = 13108 with res_idx 186 | MOST CONSERVED: b'W' | PDB-res 180-189\n",
      "STRAND #9: S199 @ SSE residue 2 | q = 14108 with res_idx 198 | MOST CONSERVED: b'W' | PDB-res 197-200\n",
      "STRAND #10: H204 @ SSE residue 0 | q = 14106 with res_idx 203 | MOST CONSERVED: b'C' | PDB-res 204-210\n",
      "STRAND #11: N218 @ SSE residue 5 | q = 13822 with res_idx 217 | MOST CONSERVED: b'C' | PDB-res 213-218\n",
      "STRAND #12: M227 @ SSE residue 4 | q = 13563 with res_idx 226 | MOST CONSERVED: b'L' | PDB-res 223-230\n",
      "__________\n",
      "{'S1': 65, 'S2': 74, 'S3': 88, 'S4': 107, 'S5': 130, 'S6': 149, 'S7': 166, 'S8': 186, 'S9': 198, 'S10': 203, 'S11': 217, 'S12': 226} {'S1': 4022, 'S2': 8419, 'S3': 7880, 'S4': 8573, 'S5': 8399, 'S6': 10820, 'S7': 9341, 'S8': 13108, 'S9': 14108, 'S10': 14106, 'S11': 13822, 'S12': 13563} {'S1': 66, 'S2': 75, 'S3': 89, 'S4': 108, 'S5': 131, 'S6': 150, 'S7': 167, 'S8': 187, 'S9': 199, 'S10': 204, 'S11': 218, 'S12': 227}\n",
      "[NOTE]: ../A0A2Y9F628_A.struc_aln.fa overwritten.\n",
      "HELIX  #1: T417 @ SSE residue 2 | q = 4997 with res_idx 6 | MOST CONSERVED: b'S' | PDB-res 415-425\n",
      "HELIX  #2: L440 @ SSE residue 8 | q = 9376 with res_idx 29 | MOST CONSERVED: b'L' | PDB-res 432-449\n",
      "HELIX  #3: D455 @ SSE residue 2 | q = 8612 with res_idx 44 | MOST CONSERVED: b'D' | PDB-res 453-468\n",
      "HELIX  #4: M490 @ SSE residue 14 | q = 9045 with res_idx 79 | MOST CONSERVED: b'L' | PDB-res 476-490\n",
      "HELIX  #5: Q515 @ SSE residue 21 | q = 9470 with res_idx 104 | MOST CONSERVED: b'E' | PDB-res 494-524\n",
      "__________\n",
      "{'H1': 6, 'H2': 29, 'H3': 44, 'H4': 79, 'H5': 104} {'H1': 4997, 'H2': 9376, 'H3': 8612, 'H4': 9045, 'H5': 9470} {'H1': 417, 'H2': 440, 'H3': 455, 'H4': 490, 'H5': 515}\n",
      "[NOTE]: ../A0A7K6E127_C.struc_aln.fa overwritten.\n",
      "HELIX  #1: L459 @ SSE residue 5 | q = 3800 with res_idx 11 | MOST CONSERVED: b'L' | PDB-res 454-468\n",
      "HELIX  #2: L485 @ SSE residue 10 | q = 9625 with res_idx 37 | MOST CONSERVED: b'L' | PDB-res 475-491\n",
      "HELIX  #3: D499 @ SSE residue 2 | q = 8515 with res_idx 51 | MOST CONSERVED: b'D' | PDB-res 497-516\n",
      "HELIX  #4: L522 @ SSE residue 3 | q = 2147 with res_idx 74 | MOST CONSERVED: b'E' | PDB-res 519-525\n",
      "HELIX  #5: L542 @ SSE residue 13 | q = 9142 with res_idx 94 | MOST CONSERVED: b'L' | PDB-res 529-552\n",
      "HELIX  #6: L563 @ SSE residue 4 | q = 9131 with res_idx 115 | MOST CONSERVED: b'L' | PDB-res 559-580\n",
      "__________\n",
      "{'H1': 11, 'H2': 37, 'H3': 51, 'H4': 74, 'H5': 94, 'H6': 115} {'H1': 3800, 'H2': 9625, 'H3': 8515, 'H4': 2147, 'H5': 9142, 'H6': 9131} {'H1': 459, 'H2': 485, 'H3': 499, 'H4': 522, 'H5': 542, 'H6': 563}\n",
      "[NOTE]: ../A0A1A7WJQ6_D.struc_aln.fa overwritten.\n",
      "HELIX  #1: R366 @ SSE residue 0 | q = 1 with res_idx 2 | MOST CONSERVED: b'R' | PDB-res 366-381\n",
      "HELIX  #2: I391 @ SSE residue 6 | q = 4067 with res_idx 27 | MOST CONSERVED: b'V' | PDB-res 385-394\n",
      "HELIX  #3: S421 @ SSE residue 10 | q = 9012 with res_idx 57 | MOST CONSERVED: b'L' | PDB-res 411-427\n",
      "HELIX  #4: D436 @ SSE residue 2 | q = 8896 with res_idx 72 | MOST CONSERVED: b'D' | PDB-res 434-448\n",
      "HELIX  #5: I481 @ SSE residue 21 | q = 9146 with res_idx 117 | MOST CONSERVED: b'L' | PDB-res 460-492\n",
      "HELIX  #6: D507 @ SSE residue 8 | q = 9377 with res_idx 143 | MOST CONSERVED: b'E' | PDB-res 499-518\n",
      "__________\n",
      "{'H1': 2, 'H2': 27, 'H3': 57, 'H4': 72, 'H5': 117, 'H6': 143} {'H1': 1, 'H2': 4067, 'H3': 9012, 'H4': 8896, 'H5': 9146, 'H6': 9377} {'H1': 366, 'H2': 391, 'H3': 421, 'H4': 436, 'H5': 481, 'H6': 507}\n",
      "[NOTE]: ../A0A2I2YJG7_E1.struc_aln.fa overwritten.\n",
      "HELIX  #1: Q146 @ SSE residue 11 | q = 1241 with res_idx 18 | MOST CONSERVED: b'A' | PDB-res 135-147\n",
      "HELIX  #2: A163 @ SSE residue 7 | q = 7724 with res_idx 35 | MOST CONSERVED: b'D' | PDB-res 156-177\n",
      "HELIX  #3: F192 @ SSE residue 7 | q = 6182 with res_idx 64 | MOST CONSERVED: b'V' | PDB-res 185-204\n",
      "HELIX  #4: E222 @ SSE residue 15 | q = 9214 with res_idx 94 | MOST CONSERVED: b'E' | PDB-res 207-228\n",
      "__________\n",
      "{'H1': 18, 'H2': 35, 'H3': 64, 'H4': 94} {'H1': 1241, 'H2': 7724, 'H3': 6182, 'H4': 9214} {'H1': 146, 'H2': 163, 'H3': 192, 'H4': 222}\n",
      "[NOTE]: ../G1TKX5_E5.struc_aln.fa overwritten.\n",
      "HELIX  #1: S269 @ SSE residue 1 | q = 5526 with res_idx 8 | MOST CONSERVED: b'D' | PDB-res 268-283\n",
      "HELIX  #2: L304 @ SSE residue 18 | q = 8354 with res_idx 43 | MOST CONSERVED: b'L' | PDB-res 286-305\n",
      "Element length below threshold. Skipping. [47 51]\n",
      "HELIX  #4: L326 @ SSE residue 11 | q = 8732 with res_idx 65 | MOST CONSERVED: b'L' | PDB-res 315-338\n",
      "__________\n",
      "{'H1': 8, 'H2': 43, 'H3': 65} {'H1': 5526, 'H2': 8354, 'H3': 8732} {'H1': 269, 'H2': 304, 'H3': 326}\n",
      "[NOTE]: ../A0A7L3N0A5_F5.struc_aln.fa overwritten.\n",
      "HELIX  #1: T534 @ SSE residue 7 | q = 4853 with res_idx 8 | MOST CONSERVED: b'Q' | PDB-res 527-541\n",
      "HELIX  #2: L556 @ SSE residue 8 | q = 9353 with res_idx 30 | MOST CONSERVED: b'L' | PDB-res 548-566\n",
      "HELIX  #3: N573 @ SSE residue 2 | q = 8972 with res_idx 47 | MOST CONSERVED: b'D' | PDB-res 571-585\n",
      "HELIX  #4: V607 @ SSE residue 14 | q = 8956 with res_idx 81 | MOST CONSERVED: b'L' | PDB-res 593-619\n",
      "HELIX  #5: E633 @ SSE residue 8 | q = 9332 with res_idx 107 | MOST CONSERVED: b'E' | PDB-res 625-638\n",
      "__________\n",
      "{'H1': 8, 'H2': 30, 'H3': 47, 'H4': 81, 'H5': 107} {'H1': 4853, 'H2': 9353, 'H3': 8972, 'H4': 8956, 'H5': 9332} {'H1': 534, 'H2': 556, 'H3': 573, 'H4': 607, 'H5': 633}\n",
      "[NOTE]: ../W5PQ70_F4.struc_aln.fa overwritten.\n",
      "Element length below threshold. Skipping. [0 4]\n",
      "Element length below threshold. Skipping. [ 9 11]\n",
      "HELIX  #3: Q136 @ SSE residue 5 | q = 4737 with res_idx 41 | MOST CONSERVED: b'G' | PDB-res 131-138\n",
      "HELIX  #4: I146 @ SSE residue 2 | q = 9120 with res_idx 51 | MOST CONSERVED: b'L' | PDB-res 144-152\n",
      "HELIX  #5: N159 @ SSE residue 2 | q = 8827 with res_idx 64 | MOST CONSERVED: b'D' | PDB-res 157-174\n",
      "HELIX  #6: L194 @ SSE residue 14 | q = 9147 with res_idx 99 | MOST CONSERVED: b'L' | PDB-res 180-204\n",
      "HELIX  #7: N219 @ SSE residue 10 | q = 9573 with res_idx 124 | MOST CONSERVED: b'E' | PDB-res 209-224\n",
      "__________\n",
      "{'H1': 41, 'H2': 51, 'H3': 64, 'H4': 99, 'H5': 124} {'H1': 4737, 'H2': 9120, 'H3': 8827, 'H4': 9147, 'H5': 9573} {'H1': 136, 'H2': 146, 'H3': 159, 'H4': 194, 'H5': 219}\n",
      "[NOTE]: ../A0A2K5Y1I7_G7.struc_aln.fa overwritten.\n",
      "HELIX  #1: E149 @ SSE residue 5 | q = 4851 with res_idx 8 | MOST CONSERVED: b'Q' | PDB-res 144-152\n",
      "HELIX  #2: V165 @ SSE residue 7 | q = 9289 with res_idx 24 | MOST CONSERVED: b'L' | PDB-res 158-168\n",
      "Element length below threshold. Skipping. [31 33]\n",
      "HELIX  #4: N179 @ SSE residue 2 | q = 8780 with res_idx 38 | MOST CONSERVED: b'D' | PDB-res 177-195\n",
      "HELIX  #5: L213 @ SSE residue 14 | q = 8699 with res_idx 72 | MOST CONSERVED: b'L' | PDB-res 199-213\n",
      "HELIX  #6: F220 @ SSE residue 3 | q = 8197 with res_idx 79 | MOST CONSERVED: b'W' | PDB-res 217-225\n",
      "HELIX  #7: E240 @ SSE residue 11 | q = 8537 with res_idx 99 | MOST CONSERVED: b'E' | PDB-res 229-244\n",
      "__________\n",
      "{'H1': 8, 'H2': 24, 'H3': 38, 'H4': 72, 'H5': 79, 'H6': 99} {'H1': 4851, 'H2': 9289, 'H3': 8780, 'H4': 8699, 'H5': 8197, 'H6': 8537} {'H1': 149, 'H2': 165, 'H3': 179, 'H4': 213, 'H5': 220, 'H6': 240}\n",
      "[NOTE]: ../A0A452HCU9_L.struc_aln.fa overwritten.\n",
      "HELIX  #1: Q495 @ SSE residue 7 | q = 4652 with res_idx 14 | MOST CONSERVED: b'Q' | PDB-res 488-499\n",
      "HELIX  #2: L510 @ SSE residue 7 | q = 9075 with res_idx 29 | MOST CONSERVED: b'L' | PDB-res 503-515\n",
      "HELIX  #3: D522 @ SSE residue 2 | q = 8530 with res_idx 41 | MOST CONSERVED: b'D' | PDB-res 520-543\n",
      "HELIX  #4: L581 @ SSE residue 29 | q = 9083 with res_idx 100 | MOST CONSERVED: b'L' | PDB-res 552-591\n",
      "HELIX  #5: E609 @ SSE residue 15 | q = 9228 with res_idx 128 | MOST CONSERVED: b'E' | PDB-res 594-617\n",
      "__________\n",
      "{'H1': 14, 'H2': 29, 'H3': 41, 'H4': 100, 'H5': 128} {'H1': 4652, 'H2': 9075, 'H3': 8530, 'H4': 9083, 'H5': 9228} {'H1': 495, 'H2': 510, 'H3': 522, 'H4': 581, 'H5': 609}\n",
      "[NOTE]: ../A0A7L3KTA8_L4.struc_aln.fa overwritten.\n",
      "HELIX  #1: H192 @ SSE residue 10 | q = 4105 with res_idx 15 | MOST CONSERVED: b'S' | PDB-res 182-201\n",
      "HELIX  #2: I213 @ SSE residue 7 | q = 9437 with res_idx 36 | MOST CONSERVED: b'L' | PDB-res 206-217\n",
      "HELIX  #3: E225 @ SSE residue 2 | q = 8628 with res_idx 48 | MOST CONSERVED: b'D' | PDB-res 223-235\n",
      "Element length below threshold. Skipping. [62 65]\n",
      "HELIX  #5: N265 @ SSE residue 16 | q = 7325 with res_idx 88 | MOST CONSERVED: b'N' | PDB-res 249-266\n",
      "HELIX  #6: W275 @ SSE residue 6 | q = 8711 with res_idx 98 | MOST CONSERVED: b'W' | PDB-res 269-276\n",
      "HELIX  #7: E295 @ SSE residue 15 | q = 9765 with res_idx 118 | MOST CONSERVED: b'E' | PDB-res 280-303\n",
      "__________\n",
      "{'H1': 15, 'H2': 36, 'H3': 48, 'H4': 88, 'H5': 98, 'H6': 118} {'H1': 4105, 'H2': 9437, 'H3': 8628, 'H4': 7325, 'H5': 8711, 'H6': 9765} {'H1': 192, 'H2': 213, 'H3': 225, 'H4': 265, 'H5': 275, 'H6': 295}\n",
      "[NOTE]: ../A0A6Q2XYK2_V.struc_aln.fa overwritten.\n",
      "HELIX  #1: D529 @ SSE residue 10 | q = 4789 with res_idx 13 | MOST CONSERVED: b'Q' | PDB-res 519-531\n",
      "HELIX  #2: M547 @ SSE residue 10 | q = 8899 with res_idx 31 | MOST CONSERVED: b'L' | PDB-res 537-551\n",
      "HELIX  #3: Q559 @ SSE residue 2 | q = 8667 with res_idx 43 | MOST CONSERVED: b'D' | PDB-res 557-565\n",
      "HELIX  #4: A590 @ SSE residue 14 | q = 7832 with res_idx 74 | MOST CONSERVED: b'L' | PDB-res 576-590\n",
      "HELIX  #5: L603 @ SSE residue 2 | q = 7209 with res_idx 87 | MOST CONSERVED: b'L' | PDB-res 601-614\n",
      "__________\n",
      "{'H1': 13, 'H2': 31, 'H3': 43, 'H4': 74, 'H5': 87} {'H1': 4789, 'H2': 8899, 'H3': 8667, 'H4': 7832, 'H5': 7209} {'H1': 529, 'H2': 547, 'H3': 559, 'H4': 590, 'H5': 603}\n",
      "{'E5b': {'S1': 325, 'S2': 334, 'S3': 351, 'S4': 360, 'S5': 382, 'S6': 410, 'S7': 414, 'S8': 431, 'S9': 454, 'S10': 460, 'S11': 465, 'S12': 479, 'S13': 488}, 'G5b': {'S1': 66, 'S2': 75, 'S3': 89, 'S4': 108, 'S5': 131, 'S6': 150, 'S7': 167, 'S8': 187, 'S9': 199, 'S10': 204, 'S11': 218, 'S12': 227}, 'A': {'H1': 417, 'H2': 440, 'H3': 455, 'H4': 490, 'H5': 515}, 'C': {'H1': 459, 'H2': 485, 'H3': 499, 'H4': 522, 'H5': 542, 'H6': 563}, 'D': {'H1': 366, 'H2': 391, 'H3': 421, 'H4': 436, 'H5': 481, 'H6': 507}, 'E1': {'H1': 146, 'H2': 163, 'H3': 192, 'H4': 222}, 'E5': {'H1': 269, 'H2': 304, 'H3': 326}, 'F5': {'H1': 534, 'H2': 556, 'H3': 573, 'H4': 607, 'H5': 633}, 'F4': {'H1': 136, 'H2': 146, 'H3': 159, 'H4': 194, 'H5': 219}, 'G7': {'H1': 149, 'H2': 165, 'H3': 179, 'H4': 213, 'H5': 220, 'H6': 240}, 'L': {'H1': 495, 'H2': 510, 'H3': 522, 'H4': 581, 'H5': 609}, 'L4': {'H1': 192, 'H2': 213, 'H3': 225, 'H4': 265, 'H5': 275, 'H6': 295}, 'V': {'H1': 529, 'H2': 547, 'H3': 559, 'H4': 590, 'H5': 603}}\n",
      "{'E5b': {'S1': 99, 'S2': 108, 'S3': 125, 'S4': 134, 'S5': 156, 'S6': 184, 'S7': 188, 'S8': 205, 'S9': 228, 'S10': 234, 'S11': 239, 'S12': 253, 'S13': 262}, 'G5b': {'S1': 65, 'S2': 74, 'S3': 88, 'S4': 107, 'S5': 130, 'S6': 149, 'S7': 166, 'S8': 186, 'S9': 198, 'S10': 203, 'S11': 217, 'S12': 226}, 'A': {'H1': 6, 'H2': 29, 'H3': 44, 'H4': 79, 'H5': 104}, 'C': {'H1': 11, 'H2': 37, 'H3': 51, 'H4': 74, 'H5': 94, 'H6': 115}, 'D': {'H1': 2, 'H2': 27, 'H3': 57, 'H4': 72, 'H5': 117, 'H6': 143}, 'E1': {'H1': 18, 'H2': 35, 'H3': 64, 'H4': 94}, 'E5': {'H1': 8, 'H2': 43, 'H3': 65}, 'F5': {'H1': 8, 'H2': 30, 'H3': 47, 'H4': 81, 'H5': 107}, 'F4': {'H1': 41, 'H2': 51, 'H3': 64, 'H4': 99, 'H5': 124}, 'G7': {'H1': 8, 'H2': 24, 'H3': 38, 'H4': 72, 'H5': 79, 'H6': 99}, 'L': {'H1': 14, 'H2': 29, 'H3': 41, 'H4': 100, 'H5': 128}, 'L4': {'H1': 15, 'H2': 36, 'H3': 48, 'H4': 88, 'H5': 98, 'H6': 118}, 'V': {'H1': 13, 'H2': 31, 'H3': 43, 'H4': 74, 'H5': 87}}\n",
      "{'H1': 0, 'H2': 1, 'H3': 2, 'H4': 3, 'H5': 4, 'H6': 5} 6\n",
      "(6, 11)\n",
      "{'H1': 4997, 'H2': 9376, 'H3': 8612, 'H4': 9045, 'H5': 9470}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "{'H1': 3800, 'H2': 9625, 'H3': 8515, 'H4': 2147, 'H5': 9142, 'H6': 9131}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "H6\n",
      "{'H1': 1, 'H2': 4067, 'H3': 9012, 'H4': 8896, 'H5': 9146, 'H6': 9377}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "H6\n",
      "{'H1': 1241, 'H2': 7724, 'H3': 6182, 'H4': 9214}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "{'H1': 5526, 'H2': 8354, 'H3': 8732}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "{'H1': 4853, 'H2': 9353, 'H3': 8972, 'H4': 8956, 'H5': 9332}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "{'H1': 4737, 'H2': 9120, 'H3': 8827, 'H4': 9147, 'H5': 9573}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "{'H1': 4851, 'H2': 9289, 'H3': 8780, 'H4': 8699, 'H5': 8197, 'H6': 8537}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "H6\n",
      "{'H1': 4652, 'H2': 9075, 'H3': 8530, 'H4': 9083, 'H5': 9228}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "{'H1': 4105, 'H2': 9437, 'H3': 8628, 'H4': 7325, 'H5': 8711, 'H6': 9765}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n",
      "H6\n",
      "{'H1': 4789, 'H2': 8899, 'H3': 8667, 'H4': 7832, 'H5': 7209}\n",
      "H1\n",
      "H2\n",
      "H3\n",
      "H4\n",
      "H5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scwabbel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hildilab/projects/agpcr_nom/repo/template_testing.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hildilab/projects/agpcr_nom/repo/template_testing.ipynb#W5sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         \u001b[39mprint\u001b[39m(v)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hildilab/projects/agpcr_nom/repo/template_testing.ipynb#W5sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         hasAnchor[anchor_col[v], fam_count] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hildilab/projects/agpcr_nom/repo/template_testing.ipynb#W5sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m scwabbel\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scwabbel' is not defined"
     ]
    }
   ],
   "source": [
    "r1_templates = {'sdb':['A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula', 'b', '../A0A3P8S994_sdb'],\n",
    "                    'A': ['A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus', 'a', '../A0A2Y9F628_A_sda'], \n",
    "                    'B': ['A0A4W6DVA0-A0A4W6DVA0_LATCA-AGRB1b-Lates_calcarifer', 'a', '../A0A4W6DVA0_B_sda'], \n",
    "                    'C': ['A0A7K6E127-A0A7K6E127_9PASS-CELR3protein-Grantiella_picta.', 'a', '../A0A7K6E127_C_sda'], \n",
    "                    'D': ['A0A1A7WJQ6-A0A1A7WJQ6_9TELE-GR144-Iconisemion_striatum.', 'a', '../A0A1A7WJQ6_D_sda'], \n",
    "                    'E': ['A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula', 'a', '../A0A3P8S994_E_sda'], \n",
    "                    'F': ['A0A452IH20-A0A452IH20_9SAUR-AGRF5-Gopherus_agassizii', 'a', '../A0A452IH20_F_sda'], \n",
    "                    'G': ['A0A1W4WJB1-A0A1W4WJB1_AGRPL-AGRG6-likeisoformX1-Agrilus_planipennis', 'a', '../A0A1W4WJB1_G_sda'], \n",
    "                    'L': ['A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii', 'a', '../A0A452HCU9_L_sda'], \n",
    "                    'V': ['A0A6Q2XYK2-A0A6Q2XYK2_ESOLU-AGRV1-Esox_lucius', 'a', '../A0A6Q2XYK2_V_sda'],\n",
    "                    'X': [\"A0A6F9A857-A0A6F9A857_9TELE-Uncharacterizedprotein-Coregonus_sp._'balchen'.\", 'a', '../A0A6F9A857_X_sda']}\n",
    "\n",
    "# fuse sda_templates and sdb_templates together to be in the form of:\n",
    "#    'A': ['A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus', 'a', '../A0A2Y9F628_A_sda'],\n",
    "templates = {}\n",
    "for t_id, t_name in {**sdb_templates, **sda_templates}.items():\n",
    "    if \"b\" in t_id: sd = 'b'\n",
    "    else:           sd = 'a'\n",
    "    \n",
    "    folder_string = f\"../{t_id}_{t_name.split('-')[0]}_sd{sd}\"\n",
    "    templates[t_id] = [t_name, sd, folder_string]\n",
    "\n",
    "print(\"Fused SDA and SDB templates into a single dictionary:\", templates)\n",
    "\n",
    "template_anchors = {}\n",
    "template_quality = {}\n",
    "template_indices = []\n",
    "\n",
    "all_indices = []\n",
    "for k, v in templates.items():\n",
    "\n",
    "    if 'b' in k:\n",
    "        threshold = 1\n",
    "    else:\n",
    "        threshold = 4\n",
    "    \n",
    "    template_gain = get_gain(v[0].split(\"-\")[0], valid_collection.collection)\n",
    "    #raw_anchors, a_qual, indices, anchors = get_template_information(v[0].split(\"-\")[0], valid_collection, v[1], threshold=threshold)\n",
    "    structural_alignment = tf.construct_structural_alignment(template_gain_domain=template_gain,\n",
    "                                                             list_of_gain_obj=valid_collection.collection,\n",
    "                                                             gain_indices=range(len(valid_collection.collection)),\n",
    "                                                             gesamt_folder=v[2],\n",
    "                                                             outfile=f'../{v[0].split(\"-\")[0]}_{k}.struc_aln.fa',\n",
    "                                                             debug=False)\n",
    "    #print(structural_alignment)\n",
    "    a_qual, indices, anchors = get_struc_aln_anchors(gain=template_gain,\n",
    "                                                     aln_dict=structural_alignment,\n",
    "                                                     subdomain=v[1],\n",
    "                                                     threshold=threshold)\n",
    "    print(a_qual, indices, anchors)\n",
    "    template_anchors[k] = anchors\n",
    "    template_quality[k] = a_qual\n",
    "    if 'b' in k:\n",
    "        continue\n",
    "    for i in indices:\n",
    "        template_indices.append(i)\n",
    "    all_indices.append(indices)\n",
    "\n",
    "print(template_anchors)\n",
    "print(template_quality)\n",
    "a,b  = np.unique(template_indices, return_counts=True)\n",
    "a_counts = dict(zip(a,b)) \n",
    "anchor_col = {x:i for i,x in enumerate(a)}\n",
    "print(anchor_col, len(a))\n",
    "hasAnchor = np.zeros(shape=(len(a), len(all_indices)))\n",
    "print(hasAnchor.shape)\n",
    "for fam_count, indices in enumerate(all_indices):\n",
    "    print(indices)\n",
    "    for v in indices:\n",
    "        print(v)\n",
    "        hasAnchor[anchor_col[v], fam_count] = 1\n",
    "scwabbel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the pairwise GESAMT, we can use the resulting OUT and PDB files for analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a,b)\n",
    "# Plot the anchors with their respective alignment columns\n",
    "# This won't work with the StAl-based anchors, since we have one alignment for each template and the index is simply the residue index\n",
    "fig = plt.figure(figsize=[4,4], facecolor='w')\n",
    "im = plt.imshow(hasAnchor.T, cmap='gray')\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(range(len(a)))\n",
    "ax.set_yticks(range(len(templates.keys())))\n",
    "ax.set_xticklabels(a, rotation=90)\n",
    "ax.set_yticklabels(templates.keys())\n",
    "ax.set_xticks(np.arange(-.5, len(a), 1), minor=True)\n",
    "ax.set_yticks(np.arange(-.5, len(templates.keys()), 1), minor=True)\n",
    "plt.xlabel(\"Helix Anchor column\")\n",
    "plt.ylabel(\"Subfamily SDA Template\")\n",
    "ax.grid(which='minor', linewidth=2)\n",
    "plt.savefig(\"../r2_StAl_sda_template_anchors.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_list = [tf.get_agpcr_type(gain.name) for gain in valid_collection.collection]\n",
    "name_list = [gain.name for gain in valid_collection.collection]\n",
    "subfam_list = [x[0] for x in fam_list]\n",
    "receptors, counts  = np.unique(fam_list, return_counts=True)\n",
    "r_list = list(zip(receptors,counts))\n",
    "print(r_list)\n",
    "print(receptors)\n",
    "fam_counts = {}\n",
    "for prot in fam_list:\n",
    "    fam = prot[0]\n",
    "    if fam not in fam_counts.keys():\n",
    "        fam_counts[fam] = 0\n",
    "    fam_counts[fam] += 1\n",
    "\n",
    "print(fam_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match everything for each subfamily.\n",
    "#print(subfam_list)\n",
    "\n",
    "y = len(r_list)\n",
    "# famstring\n",
    "template_ids = list(templates.keys())\n",
    "\n",
    "t_occupancies = {}\n",
    "t_distances = {}\n",
    "unmatched = {}\n",
    "unmatched_counters = {}\n",
    "for t_id in template_ids:\n",
    "    t_anchors = template_anchors[t_id]\n",
    "    # SDB modified. t_anchors = {'S1': 324, 'S2': 335, 'S3': 353, 'S4': 359, 'S5': 381, 'S6': 409, 'S7': 414, 'S8': 436, 'S9': 453, 'S10': 459, 'S11': 470, 'S12': 478, 'S13': 487}\n",
    "    #t_anchors = {'S1': 324, 'S2': 335, 'S3': 349, 'S4': 359, 'S5': 381, 'S6': 409, 'S7': 414, 'S8': 436, 'S9': 453, 'S10': 459, 'S11': 466, 'S12': 478, 'S13': 487}\n",
    "    t_quality = template_quality[t_id]\n",
    "    t_folder = templates[t_id][-1]\n",
    "    n_anch = len(t_anchors.keys())\n",
    "    u_list = np.zeros(shape=(y), dtype=dict)\n",
    "    u_counters = np.zeros(shape=(y), dtype=int)\n",
    "    print(t_anchors)\n",
    "    anchor_index = {k:i for i, k in enumerate(t_anchors.keys())}\n",
    "    assigned_anchor_freq = np.zeros(shape=(len(receptors),n_anch))\n",
    "    all_anchor_averages = np.full(shape=(y,n_anch), fill_value=None)\n",
    "    all_anchor_occupancy = np.zeros(shape=(y,n_anch))\n",
    "\n",
    "    if 'b' in t_id: sd_string = 'sdb'\n",
    "    else: sd_string = 'sda'\n",
    "\n",
    "    for fam_idx, r in enumerate(receptors):# in enumerate('ABCDEFGLVX'):\n",
    "        gain_subset = [ gain for i, gain in enumerate(valid_collection.collection) if fam_list[i] == r ]#subfam_list[i]==r ]\n",
    "        gain_idx_list = [ i for i,gain in enumerate(fam_list) if gain == r ]\n",
    "        #print(r, len(gain_subset))\n",
    "\n",
    "        element_occupation = {k:0 for k in t_anchors.keys()}\n",
    "\n",
    "        for key, val in element_occupation.items():\n",
    "            assigned_anchor_freq[fam_idx, anchor_index[key]] = float(val)/len(gain_subset)\n",
    "        #DEBUG:\n",
    "        #for gain in gain_subset: \n",
    "        #    print(gain.name, [hel for hel in gain.sda_helices if hel[0] < gain.subdomain_boundary-gain.start])\n",
    "        \n",
    "        fam_distances, fam_matched_anchors, unmatched_elements, unmatched_counter = tf.gain_set_to_template(gain_subset, \n",
    "                                                                                                            gain_idx_list, \n",
    "                                                                                                            t_anchors, \n",
    "                                                                                                            t_folder, \n",
    "                                                                                                            penalty=None,\n",
    "                                                                                                            subdomain=sd_string,\n",
    "                                                                                                            return_unmatched_mode='all', \n",
    "                                                                                                            debug=False)\n",
    "        #print(\"DEBUG: ROOT\" , unmatched_elements)\n",
    "        mean_dist = np.empty(shape=(n_anch))\n",
    "        occ = np.zeros(shape=(n_anch))\n",
    "        \n",
    "        for j in range(n_anch):\n",
    "            occ_values = np.array([d for d in fam_distances[:,j] if d is not None])\n",
    "            if len(occ_values) != 0:\n",
    "                mean_dist[j] = round(np.mean(occ_values), 3)\n",
    "                occ[j] = round(np.count_nonzero(fam_distances[:,j])/len(gain_idx_list), 3)\n",
    "        all_anchor_averages[fam_idx,:] = mean_dist #np.mean(fam_distances, axis=0)\n",
    "        all_anchor_occupancy[fam_idx,:] = occ\n",
    "        u_counters[fam_idx] = unmatched_counter\n",
    "        u_list[fam_idx] = unmatched_elements\n",
    "        #print(all_anchor_averages)\n",
    "        #print(all_anchor_occupancy)\n",
    "    print(u_list.shape) # u_list is a list of dicts.\n",
    "    print(type(u_list[0]), type(u_list[1]))\n",
    "    print(f\"Done with Template {t_id}.\\n\", \"_\"*30)\n",
    "\n",
    "    t_distances[t_id] = all_anchor_averages\n",
    "    t_occupancies[t_id] = all_anchor_occupancy\n",
    "    unmatched[t_id] = u_list\n",
    "    unmatched_counters[t_id] = u_counters\n",
    "#print(unmatched_counters)\n",
    "#print(type(unmatched))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the OCCUPANCY\n",
    "for t_id in [\"F5\"]:#template_ids:\n",
    "    t_anchors = template_anchors[t_id]\n",
    "    # SDB modfied anchors : t_anchors = {'S1': 324, 'S2': 335, 'S3': 353, 'S4': 359, 'S5': 381, 'S6': 409, 'S7': 414, 'S8': 436, 'S9': 453, 'S10': 459, 'S11': 470, 'S12': 478, 'S13': 487}\n",
    "    #t_anchors = {'S1': 324, 'S2': 335, 'S3': 349, 'S4': 359, 'S5': 381, 'S6': 409, 'S7': 414, 'S8': 436, 'S9': 453, 'S10': 459, 'S11': 466, 'S12': 478, 'S13': 487}\n",
    "    n_anch = len(t_anchors.keys())\n",
    "    t_anchor_freqs = t_occupancies[t_id]\n",
    "    u_counters = unmatched_counters[t_id]\n",
    "    fig = plt.figure(figsize=[6,10], facecolor='w')\n",
    "    #plt.yticks(ticks = range(ydim), labels= [f'ADGR{f}' for f in 'ABCDEFGLVX'])\n",
    "    plt.title(f\"Template Match for : {t_id}\")\n",
    "    plt.yticks(ticks = range(len(r_list)), labels= [f'{i[0]}:{i[1]} (u:{u_counters[x]})' for x,i in enumerate(r_list)])\n",
    "    #plt.yticks(ticks = range(len(r_list)), labels= [f'{i[0]}:{i[1]}' for x,i in enumerate(r_list)])\n",
    "    plt.xticks(ticks = range(n_anch), labels=t_anchors.keys(), rotation=90)\n",
    "    #plt.imshow(t_anchor_freqs, cmap='summer')\n",
    "    distances = np.zeros(shape=(len(r_list), n_anch), dtype=float)\n",
    "    #t_dists = t_distances[t_id]\n",
    "    #for i,l in enumerate(t_dists):\n",
    "    #    distances[i,:] = l\n",
    "    #plt.imshow(distances, cmap='spring')\n",
    "    plt.imshow(t_anchor_freqs, cmap='summer')\n",
    "    cbar = plt.colorbar(shrink=0.5)\n",
    "    cbar.set_label('Relative Occupancy')\n",
    "    #cbar.set_label('AA-Distance')\n",
    "    ydim = len(r_list)\n",
    "    for y in range(ydim):\n",
    "        for x in range(n_anch):\n",
    "            if t_anchor_freqs[y,x] > 0.001:\n",
    "                pass\n",
    "            else:\n",
    "                plt.text(x,y,'x', horizontalalignment='center', verticalalignment='center', fontsize=18,color='k')\n",
    "    plt.savefig(f'r2_StAl{t_id}_occ.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DISTANCES\n",
    "for t_id in template_ids[-1:]:\n",
    "    t_anchors = template_anchors[t_id]\n",
    "    # SDB modfied anchors : t_anchors = {'S1': 324, 'S2': 335, 'S3': 353, 'S4': 359, 'S5': 381, 'S6': 409, 'S7': 414, 'S8': 436, 'S9': 453, 'S10': 459, 'S11': 470, 'S12': 478, 'S13': 487}\n",
    "    #t_anchors = {'S1': 324, 'S2': 335, 'S3': 349, 'S4': 359, 'S5': 381, 'S6': 409, 'S7': 414, 'S8': 436, 'S9': 453, 'S10': 459, 'S11': 466, 'S12': 478, 'S13': 487}\n",
    "    n_anch = len(t_anchors.keys())\n",
    "    t_anchor_freqs = t_occupancies[t_id]\n",
    "    u_counters = unmatched_counters[t_id]\n",
    "    fig = plt.figure(figsize=[6,10], facecolor='w')\n",
    "    #plt.yticks(ticks = range(ydim), labels= [f'ADGR{f}' for f in r_list])\n",
    "    plt.title(f\"Template Match for : {t_id}\")\n",
    "    #plt.yticks(ticks = range(len(r_list)), labels= [f'{i[0]}:{i[1]} (u:{u_counters[x]})' for x,i in enumerate(r_list)])\n",
    "    plt.yticks(ticks = range(len(r_list)), labels= [f'{i[0]}:{i[1]}' for i in r_list])\n",
    "    plt.xticks(ticks = range(n_anch), labels=t_anchors.keys(), rotation=90)\n",
    "    #plt.imshow(t_anchor_freqs, cmap='summer')\n",
    "    distances = np.zeros(shape=(len(r_list), n_anch), dtype=float)\n",
    "    t_dists = t_distances[t_id]\n",
    "    for i,l in enumerate(t_dists):\n",
    "        distances[i,:] = l\n",
    "    plt.imshow(distances, cmap='spring')\n",
    "    #plt.imshow(t_anchor_freqs, cmap='summer')\n",
    "    cbar = plt.colorbar(shrink=0.5)\n",
    "    #cbar.set_label('Relative Occupancy')\n",
    "    cbar.set_label('AA-Distance')\n",
    "    ydim = len(r_list)\n",
    "    for y in range(ydim):\n",
    "        for x in range(n_anch):\n",
    "            if t_anchor_freqs[y,x] > 0.001:\n",
    "                pass\n",
    "            else:\n",
    "                plt.text(x,y,'x', horizontalalignment='center', verticalalignment='center', fontsize=18,color='k')\n",
    "    plt.savefig(f'r2_StAl{t_id}_dist.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"../r2_StAl_unmatched_full.txt\", 'w')\n",
    "outfile.write(\"Temp  Grp   nGrp  alnIdx  nNoMat  avgLen  %unmat\\n\")\n",
    "adress_matrix = [] # (my_template, col_names[id], value)\n",
    "col_names = {} # A1-1094: 0\n",
    "skip = 3\n",
    "\n",
    "#print(r_list, len(r_list))\n",
    "for t_index, t_id in enumerate(template_ids[skip:]):\n",
    "    u_list = unmatched[t_id]\n",
    "\n",
    "    #print(u_dict)\n",
    "    for rud_idx, receptor_unmatched_dict in enumerate(u_list):\n",
    "        \n",
    "        e_length = []\n",
    "        e_res = []\n",
    "        res_len = {}\n",
    "        all_items = []\n",
    "        #print(receptor_unmatched_dict)\n",
    "        for lst in receptor_unmatched_dict.values():\n",
    "            lengths = [int(i[2]) for i in lst]\n",
    "            e_length = e_length+lengths\n",
    "            e_res += [i[0] for i in lst]\n",
    "            \n",
    "            for i in lst:\n",
    "                if int(i[0]) not in res_len.keys():\n",
    "                    res_len[int(i[0])] = [i[2]]\n",
    "                else:\n",
    "                    res_len[int(i[0])].append(i[2])\n",
    "                all_items.append(i)\n",
    "        res_av_len = {k:np.average(v) for k,v in res_len.items()}\n",
    "\n",
    "        #print(np.average(e_length))\n",
    "        resid, ct = np.unique(e_res, return_counts=True)\n",
    "        where_many = {resid[k]:c for k,c in enumerate(ct) if c > 5}\n",
    "        #print(where_many)\n",
    "        #plt.bar(resid, ct)\n",
    "        \n",
    "        sel_length = r_list[rud_idx][1]\n",
    "        receptor_name = r_list[rud_idx][0]\n",
    "        for idx, count in enumerate(ct):\n",
    "            if count > 0.1*sel_length and res_av_len[resid[idx]] > 3.5: # more than 10% of selection have this\n",
    "\n",
    "                unindexed_freq = count/sel_length\n",
    "                column_name = f\"{receptor_name}-{str(resid[idx]).ljust(4)}\"\n",
    "                if column_name not in col_names.keys(): \n",
    "                    name_idx = len(col_names.keys())\n",
    "                    col_names[column_name] = name_idx\n",
    "                    \n",
    "                else:\n",
    "                    name_idx = col_names[column_name]\n",
    "                adress_matrix.append( (t_index, name_idx, unindexed_freq) )\n",
    "\n",
    "                outfile.write(f\"{t_id}{receptor_name.rjust(7)}{str(sel_length).rjust(8)}\")\n",
    "                outfile.write(f\"{str(resid[idx]).rjust(8)}{str(count).rjust(8)}{str(round(res_av_len[resid[idx]],1)).rjust(8)}{str(round(count*100/sel_length)).rjust(7)}%   \")\n",
    "                for value in all_items[idx]:\n",
    "                    outfile.write(str(value).rjust(8))#plt.bar(resid[idx], count)\n",
    "                outfile.write(\"\\n\")\n",
    "                #plt.annotate(f\"{round(res_av_len[resid[idx]],1)}\", (resid[idx],count))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can construct a DataFrame from this shizzle\n",
    "unmatched_matrix = np.zeros(shape=(len(template_ids)-skip, len(col_names.keys())), dtype=float)\n",
    "for item in adress_matrix:\n",
    "    unmatched_matrix[item[0],item[1]] = item[2]\n",
    "# Sort the matrix to match the receptor order in $receptors\n",
    "sorted_unmatched_matrix = np.zeros(shape=(len(template_ids)-skip, len(col_names.keys())), dtype=float)\n",
    "new_order = sorted(range(len(col_names.keys())), key=lambda k: list(col_names.keys())[k])\n",
    "#print(new_order)\n",
    "for data_col in range(len(col_names.keys())):\n",
    "    sorted_unmatched_matrix[:,data_col] = unmatched_matrix[:,new_order[data_col]]\n",
    "\n",
    "fig = plt.figure(figsize=[12,4], facecolor='w')\n",
    "ax = plt.gca()\n",
    "ax.imshow(sorted_unmatched_matrix, cmap='binary')\n",
    "plt.xticks(ticks = range(len(col_names.keys())), labels = sorted(col_names.keys()) ,rotation=90, fontsize=4, verticalalignment='top')\n",
    "plt.yticks(ticks = range(len(template_ids)-skip), labels=template_ids[skip:], fontsize=4)\n",
    "stored_ki = 'A1'\n",
    "r_bounds = []\n",
    "for i, ki in enumerate(sorted(col_names.keys())):\n",
    "    r = ki.split(\"-\")[0]\n",
    "    if r != stored_ki:\n",
    "        stored_ki = r\n",
    "        r_bounds.append(i)\n",
    "for b in r_bounds:\n",
    "    plt.vlines(b-0.5, -0.5, len(template_ids)-skip-0.5, color='r', linewidth=0.5)\n",
    "plt.savefig(\"../r2_StAl_template_match1.png\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[4,12], facecolor='w')\n",
    "plt.imshow(sorted_unmatched_matrix)\n",
    "stored_ki = 'A1'\n",
    "r_bounds = []\n",
    "for i, ki in enumerate(sorted(col_names.keys())):\n",
    "    r = ki.split(\"-\")[0]\n",
    "    if r != stored_ki:\n",
    "        stored_ki = r\n",
    "        r_bounds.append(i)\n",
    "\n",
    "#for b in r_bounds:\n",
    "#    plt.vlines(b, 0, len(template_ids)-1, color='w', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel2pymol(receptor, target_folder, find=False, stride=1):\n",
    "    id_list = []\n",
    "    for r in receptors:# in enumerate('ABCDEFGLVX'):\n",
    "        if r != receptor:\n",
    "            continue\n",
    "        gain_subset = [ gain for i, gain in enumerate(valid_collection.collection) if fam_list[i] == r]#subfam_list[i]==r ]\n",
    "        for gain in gain_subset:\n",
    "            id_list.append(gain.name.split(\"-\")[0])\n",
    "        file_str = [(find_pdb(i, target_folder)) for i in id_list]\n",
    "        print(\"pymol\",\" \".join(file_str))\n",
    "    if find:\n",
    "        for identifier in id_list[::stride]:\n",
    "            print(f'find . -name \\\"*{identifier}*rank_1*pdb\\\" | tee -a {receptor}_found.txt')\n",
    "\n",
    "sel2pymol('F2', '../all_pdbs/', True, stride=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ydim = 40\n",
    "fig = plt.figure(figsize=[8,ydim/3], facecolor='w')\n",
    "plt.imshow(docc, cmap='spring')\n",
    "#plt.yticks(ticks = range(ydim), labels= [f'ADGR{f}' for f in 'ABCDEFGLVX'])\n",
    "plt.yticks(ticks = range(ydim), labels= [f'{i[0]}:{i[1]}' for i in r_list])\n",
    "plt.xticks(ticks = range(n_anch), labels= allsse, rotation=90)\n",
    "\n",
    "all_anchor_averages # 10,21\n",
    "for y in range(ydim):\n",
    "    for x in range(n_anch):\n",
    "        if all_anchor_averages[y,x] > 0.0001:\n",
    "            plt.text(x,y, round(all_anchor_averages[y,x], 2), horizontalalignment='center', verticalalignment='center', fontsize=7,color='k', rotation=45)\n",
    "cbar = plt.colorbar(shrink=float(8/ydim))\n",
    "cbar.set_label('Relative Occupancy')\n",
    "plt.vlines(6.5,-0.5,ydim-0.5, color='k', linewidth=1.5)\n",
    "plt.savefig('identity_receptor_anchor_occupancy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=[8,ydim/3], facecolor='w')\n",
    "#plt.imshow(df, cmap='summer')\n",
    "im_data = np.zeros(shape=(ydim, n_anch))\n",
    "\n",
    "print(all_anchor_averages.shape)\n",
    "#plt.yticks(ticks = range(10), labels= [f'ADGR{f}' for f in 'ABCDEFGLVX'])\n",
    "plt.yticks(ticks = range(ydim), labels= [f'{i[0]}:{i[1]}' for i in r_list])\n",
    "plt.xticks(ticks = range(n_anch), labels= allsse, rotation=90)\n",
    "#all_anchor_averages # 10,21\n",
    "for y in range(ydim):\n",
    "    for x in range(n_anch):\n",
    "        if all_anchor_averages[y,x] > 0.001:\n",
    "            im_data[y,x] = all_anchor_averages[y,x]\n",
    "        else:\n",
    "            plt.text(x,y,'x', horizontalalignment='center', verticalalignment='center', fontsize=20,color='k')\n",
    "            #patches.Rectangle((x,y), 1, 1, linewidth=0.5, edgecolor='k', facecolor='w')\n",
    "plt.imshow(im_data, cmap='summer', vmax=3)\n",
    "            #plt.text(x,y, round(all_anchor_averages[y,x], 2), horizontalalignment='center', verticalalignment='center', fontsize=7,color='k', rotation=45)\n",
    "cbar = plt.colorbar(shrink=float(8)/ydim)\n",
    "cbar.set_label(r'Closest Anchor Residue Distance [$\\AA$]')\n",
    "plt.vlines(6.5,-0.5,ydim-0.5, color='k', linewidth=1.5)\n",
    "plt.savefig('identity_receptor_anchor_distance.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydim = 40\n",
    "fig = plt.figure(figsize=[8,ydim/3], facecolor='w')\n",
    "\n",
    "#plt.yticks(ticks = range(ydim), labels= [f'ADGR{f}' for f in 'ABCDEFGLVX'])\n",
    "plt.yticks(ticks = range(ydim), labels= [f'{i[0]}:{i[1]}' for i in r_list])\n",
    "plt.xticks(ticks = range(n_anch), labels= allsse, rotation=90)\n",
    "occ_values = df.to_numpy()\n",
    "is_off = np.zeros(shape=(40,26))\n",
    "print(docc.shape, all_anchor_averages.shape)\n",
    "#all_anchor_averages # 10,21\n",
    "for y in range(ydim):\n",
    "    for x in range(n_anch):\n",
    "        if all_anchor_averages[y,x] is not None and all_anchor_averages[y,x] > 1.5 and occ_values[y,x] > 0.1:\n",
    "            is_off[y,x] = 1\n",
    "            plt.text(x,y, round(all_anchor_averages[y,x], 2), horizontalalignment='center', verticalalignment='center', fontsize=7,color='k', rotation=45)\n",
    "plt.imshow(is_off, cmap='spring')\n",
    "cbar = plt.colorbar(shrink=float(8/ydim))\n",
    "cbar.set_label('Relative Occupancy')\n",
    "plt.vlines(6.5,-0.5,ydim-0.5, color='k', linewidth=1.5)\n",
    "#plt.savefig('identity_receptor_anchor_occupancy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_stats = np.zeros(shape = (n_anch, 2))\n",
    "\n",
    "for fam_idx, r in enumerate(receptors):# in enumerate('ABCDEFGLVX'):\n",
    "    print(r)\n",
    "    gain_subset = [ gain for i, gain in enumerate(valid_collection.collection) if fam_list[i] == r]#subfam_list[i]==r ]\n",
    "    gain_idx_list = [ i for i,gain in enumerate(fam_list) if gain == r ]\n",
    "    n_sse = [[len(gain.sda_helices), len(gain.sdb_sheets)] for gain in gain_subset] # (n_struc, 2)\n",
    "    n_strucs = np.mean(np.array(n_sse), axis=0)\n",
    "    print(r, round(n_strucs[0], 2), round(n_strucs[1],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new Anchor management.\n",
    "\n",
    "#\n",
    "# Use the \"max\" SDA / SDB template for generating the new anchors \n",
    "# get the center residue index for each template SSE\n",
    "for gain in valid_collection.collection:\n",
    "    if gain.name[:10] == 'A0A7K7IHI9': #SDA\n",
    "        hel_centers = []\n",
    "        for hel in gain.sda_helices: # each hel is a tuple\n",
    "            hel_centers.append( gain.start + int((hel[0]+hel[1])/2) )\n",
    "        hel_keys = [f'H{i+1}' for i in range(len(hel_centers))]\n",
    "        sda_centers = dict(zip(hel_keys, hel_centers))\n",
    "    if gain.name[:10] =='A0A3P9I6M5':\n",
    "        sheet_centers = []\n",
    "        for sheet in gain.sdb_sheets: # each hel is a tuple\n",
    "            #if sheet[1] - sheet[0] < 3:\n",
    "            #    print(gain.start+sheet[0], gain.start+sheet[1])\n",
    "            sheet_centers.append( gain.start + int((sheet[0]+sheet[1])/2) )\n",
    "        sheet_keys = [f'S{i+1}' for i in range(len(sheet_centers))]\n",
    "        sdb_centers = dict(zip(sheet_keys, sheet_centers))\n",
    "# Manually curated the centers to exclude two small strands in the CD between S6/S7 @ 707-708 and 711-713, respectively (low pLDDT here).\n",
    "sda_centers = {'H1': 313, 'H2': 328, 'H3': 359, 'H4': 383, 'H5': 409, 'H6': 424, 'H7': 444}\n",
    "sdb_centers = {'S1': 622, 'S2': 631, 'S3': 645, 'S4': 658, 'S5': 670, 'S6': 695, 'S7': 719, 'S8': 736, 'S9': 752, 'S10': 765, 'S11': 771, 'S12': 782, 'S13': 793}\n",
    "\n",
    "# Find closest residue to the center (GESAMT), note down the sequence, start, end of the matched SSE; write to FASTA\n",
    "    # A dict of dicts --> for each key, there is a dictionary inside sse_seqs['H1'][gain.name]:'seqlist'\n",
    "all_keys = list({**sda_centers, **sdb_centers}.keys())\n",
    "sse_seqs = {k:{} for k in all_keys}\n",
    "sse_extents = {k:{} for k in all_keys}\n",
    "unmatched = {k:0 for k in all_keys}\n",
    "unstructured = {k:0 for k in all_keys}\n",
    "\n",
    "for i, gain in enumerate(valid_collection.collection):\n",
    "        a_gesamt_file = f'../sda_template_aligned_files/sda_{i}.out'\n",
    "        b_gesamt_file = f'../sdb_template_aligned_files/sdb_{i}.out'\n",
    "\n",
    "        sda_matches = tf.find_anchor_matches(a_gesamt_file, sda_centers, isTarget=False)\n",
    "        sdb_matches = tf.find_anchor_matches(b_gesamt_file, sdb_centers, isTarget=False)\n",
    "        #print(sda_matches, sdb_matches)\n",
    "        hel_extents = np.full(shape = (gain.end-gain.start+1), fill_value=100)\n",
    "        she_extents = np.full(shape = (gain.end-gain.start+1), fill_value=100)\n",
    "        # Establish two matrices to match the respective residue to the index of its helix/sheet for easier matching\n",
    "        for i,element in enumerate(gain.sda_helices):\n",
    "            hel_extents[element[0]:element[1]] = i\n",
    "        for i,element in enumerate(gain.sdb_sheets):\n",
    "            she_extents[element[0]:element[1]] = i\n",
    "        # Match the corresponding closest residue to find the associated SSE with start, end and sequence\n",
    "        for sse, match in sda_matches.items():\n",
    "            if match[0] is None:\n",
    "                unmatched[sse] += 1\n",
    "                continue\n",
    "\n",
    "            sse_index = hel_extents[match[0]-gain.start]\n",
    "\n",
    "            if sse_index == 100:\n",
    "                unstructured[sse] += 1\n",
    "                continue\n",
    "\n",
    "            sse_extents[sse][gain.name] = gain.sda_helices[sse_index]\n",
    "            sse_seqs[sse][gain.name] = gain.sequence[gain.sda_helices[sse_index][0]:gain.sda_helices[sse_index][1]]\n",
    "        \n",
    "        for sse, match in sdb_matches.items():\n",
    "            if match[0] is None:\n",
    "                unmatched[sse] += 1\n",
    "                continue\n",
    "\n",
    "            sse_index = she_extents[match[0]-gain.start]\n",
    "\n",
    "            if sse_index == 100:\n",
    "                unstructured[sse] += 1\n",
    "                continue\n",
    "\n",
    "            sse_extents[sse][gain.name] = gain.sdb_sheets[sse_index]\n",
    "            sse_seqs[sse][gain.name] = gain.sequence[gain.sdb_sheets[sse_index][0]:gain.sdb_sheets[sse_index][1]]\n",
    "        \n",
    "for sse in all_keys:\n",
    "    with open(f'../sse_aln/{sse}.seqs.fa','w') as fa:\n",
    "        for name, seq in sse_seqs[sse].items():\n",
    "            fa.write(f'>{name}\\n{\"\".join(seq)}\\n')\n",
    "\n",
    "print(unmatched, '\\n', unstructured)\n",
    "#   Run MAFFT with each of the gathered sequences\n",
    "#   For each MAFFT\n",
    "#       Find the most conserved residue (Identity matrix)\n",
    "#       Set as new Anchor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for gain in valid_collection.collection:\n",
    "\n",
    "    if gain.name[:10] == 'A0A7K7IHI9': #SDA\n",
    "        sda_gain = gain\n",
    "    if gain.name[:10] =='A0A3P9I6M5': # SDB\n",
    "        sdb_gain = gain\n",
    "for i,k in enumerate(sda_centers.keys()):\n",
    "    kfile = glob.glob(f\"../sse_aln/{k}.aln.fa\")[0]\n",
    "    with open(kfile) as alnf:\n",
    "        x = alnf.readlines()[1].strip(\" \\n\")\n",
    "        kcutoff = len(x)\n",
    "    print(kcutoff)\n",
    "    aln = sse_func.read_alignment(kfile, cutoff=kcutoff)\n",
    "    h = sda_gain.sda_helices[i]\n",
    "    aln_matrix = np.array([list(seq) for seq in aln.values()])\n",
    "    kquality, kocc = calc_identity(aln_matrix)\n",
    "    '''    kquality = []\n",
    "    kocc = []\n",
    "    for col in range(aln_matrix.shape[1]):\n",
    "        chars, count = np.unique(aln_matrix[:,col], return_counts=True)\n",
    "        if chars[0] == '-':\n",
    "            q = count[1]\n",
    "        else:\n",
    "            q = count[0]\n",
    "        x = np.where(chars == '-')[0][0]\n",
    "        kocc.append(14435 - count[x])\n",
    "        kquality.append(q)'''\n",
    "    template_aln_seq = aln[sda_gain.name]\n",
    "    template_res_idx = np.argmax(kquality)\n",
    "    print(template_aln_seq, template_res_idx)\n",
    "    template_index = template_aln_seq[:template_res_idx+1]\n",
    "    t_res = template_aln_seq[template_res_idx]\n",
    "    print(template_index, t_res)\n",
    "    new = template_index\n",
    "\n",
    "    fig = plt.figure(figsize=[4,2], facecolor='w')\n",
    "    plt.bar(range(kcutoff), kquality)\n",
    "    plt.title(f'SDA TEMPLATE : {k}')\n",
    "    plt.xticks(ticks = range(kcutoff), labels=template_aln_seq, fontsize=5)\n",
    "    plt.savefig(f'../sse_aln/{k}.template1.png', dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "for i,k in enumerate(sdb_centers.keys()):\n",
    "    kfile = glob.glob(f\"../sse_aln/{k}.aln.fa\")[0]\n",
    "    with open(kfile) as alnf:\n",
    "        x = alnf.readlines()[1].strip(\" \\n\")\n",
    "        kcutoff = len(x)\n",
    "    print(kcutoff)\n",
    "    aln = sse_func.read_alignment(kfile, cutoff=kcutoff)\n",
    "    h = sdb_gain.sdb_sheets[i]\n",
    "    aln_matrix = np.array([list(seq) for seq in aln.values()])\n",
    "    kquality = []\n",
    "    kocc = []\n",
    "    kquality, kocc = calc_identity(aln_matrix)\n",
    "        \n",
    "    template_aln_seq = aln[sdb_gain.name]\n",
    "    template_res_idx = np.argmax(kquality)\n",
    "    print(template_aln_seq, template_res_idx)\n",
    "    template_index = template_aln_seq[:template_res_idx+1]\n",
    "    t_res = template_aln_seq[template_res_idx]\n",
    "    print(template_index, t_res)\n",
    "    new = template_index\n",
    "\n",
    "    fig = plt.figure(figsize=[4,2], facecolor='w')\n",
    "    plt.bar(range(kcutoff), kquality)\n",
    "    plt.title(f'SDB TEMPLATE : {k}')\n",
    "    plt.xticks(ticks = range(kcutoff), labels=template_aln_seq, fontsize=5)\n",
    "    plt.savefig(f'../sse_aln/{k}.template1.png', dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor2pdb(input_pdb, output_pdb, metric):\n",
    "    # line [61:66] = xx.xx b factor\n",
    "    # set to zero if not in metric, set to val otherwise\n",
    "    with open(input_pdb) as ipdb:\n",
    "        data = ipdb.readlines()\n",
    "    newdata = []\n",
    "    for l in data:\n",
    "        if not l.startswith(\"ATOM\"):\n",
    "            newdata.append(l)\n",
    "            continue\n",
    "        \n",
    "        resid = int(l[22:26])\n",
    "\n",
    "        if resid not in metric.keys():\n",
    "            l = l[:61]+\"00.00\"+l[66:]\n",
    "            newdata.append(l)\n",
    "            continue\n",
    "\n",
    "        l = l[:61]+f'{metric[resid]:5.2f}'+l[66:]\n",
    "        newdata.append(l)\n",
    "\n",
    "    with open(output_pdb, 'w') as opdb:\n",
    "        opdb.write(\"\".join(newdata))\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(template_anchors)\n",
    "template_ids = templates.keys()\n",
    "print(templates)\n",
    "target_folder = '../r2_f_templates/'\n",
    "outstr = []\n",
    "for t_id in template_ids:\n",
    "    print(t_id)\n",
    "    t_anchors = template_anchors[t_id]\n",
    "    t_pdb = find_pdb(templates[t_id][0], '../all_pdbs/')\n",
    "\n",
    "    t_metric = {v:1 for v in t_anchors.values()}\n",
    "    outpdb = target_folder+t_id+\".b.pdb\"\n",
    "\n",
    "    #factor2pdb(t_pdb, outpdb, t_metric)\n",
    "    outstr.append(outpdb)\n",
    "\n",
    "print(\" \".join(outstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare this to the classical anchor representation using the CONSERVATION QUALITY from MAFFT\n",
    "\"\"\"alignment_file = \"/home/hildilab/projects/agpcr_nom/app_gain_gain.mafft.fa\"\n",
    "# This only contains the sigma files for truncated (?) PDBs.\n",
    "#quality = sse_func.read_quality(quality_file)\n",
    "gps_minus_one = 6781 \n",
    "aln_cutoff = 6826 \n",
    "alignment_dict = sse_func.read_alignment(alignment_file, aln_cutoff)\n",
    "aln_matrix = np.array([list(seq) for seq in alignment_dict.values()])\n",
    "#print(aln_matrix.shape)\n",
    "quality, occ = calc_identity(aln_matrix)\"\"\"\n",
    "precalc_anchors = [ 662, 1194, 1912, 2490, 2848, 3011, 3073, 3260, #H1-H8\n",
    "            3455, 3607, 3998, 4279, 4850, 5339, #5341 S1-S6, S7 REMOVED!\n",
    "            5413, 5813, 6337, 6659, 6696, 6765, 6808] #S8-13\n",
    "precalc_anchor_occupation = [ 4594.,  6539., 11392., 13658.,  8862., 5092.,  3228., 14189., #H1-H8\n",
    "                      9413., 12760.,  9420., 11201., 12283., 3676.,#  4562. S1-S6, S7 REMOVED!\n",
    "                     13992., 12575., 13999., 14051., 14353., 9760., 14215.] #S8-13\n",
    "precalc_anchor_dict = sse_func.make_anchor_dict(precalc_anchors, 3425)\n",
    "\n",
    "print(templates)\n",
    "target_folder = '../r2_f_templates/'\n",
    "outstr = []\n",
    "for t_id in template_ids:\n",
    "    print(t_id)\n",
    "    t_anchors = template_anchors[t_id]\n",
    "    t_pdb = find_pdb(templates[t_id][0], '../all_pdbs/')\n",
    "\n",
    "    # Find the template in the valid_collection\n",
    "    for gain in valid_collection.collection:\n",
    "        if gain.name.split(\"-\")[0] == templates[t_id][0].split(\"-\")[0]:\n",
    "            _,centers,_,_ = gain.create_indexing(precalc_anchors, precalc_anchor_occupation, precalc_anchor_dict, \n",
    "                                            outdir=None, offset=0, silent=True, split_mode='single',debug=False)\n",
    "            break\n",
    "    #print(centers)\n",
    "    \n",
    "    t_metric = {v+gain.start+1:1 for v in centers.values()}\n",
    "    outpdb = target_folder+t_id+\".p.pdb\"\n",
    "\n",
    "    factor2pdb(t_pdb, outpdb, t_metric)\n",
    "    outstr.append(outpdb)\n",
    "\n",
    "print(\" \".join(outstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pdb(name, pdb_folder):\n",
    "    identifier = name.split(\"-\")[0]\n",
    "    target_pdb = glob.glob(f\"{pdb_folder}/*{identifier}*.pdb\")[0]\n",
    "    return target_pdb\n",
    "\n",
    "templates = {\n",
    "    'E5b':'A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula',\n",
    "    'G5b':'A0A6J3IBI5-A0A6J3IBI5_SAPAP-AGRG5-Sapajus_apella',\n",
    "    'A': 'A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus',\n",
    "    'C': 'A0A7K6E127-A0A7K6E127_9PASS-CELR3protein-Grantiella_picta.', \n",
    "    'D': 'A0A1A7WJQ6-A0A1A7WJQ6_9TELE-GR144-Iconisemion_striatum.', \n",
    "    'E1': 'A0A2I2YJG7-A0A2I2YJG7_GORGO-AGRE1-Gorilla_gorilla_gorilla', \n",
    "    'E5': 'G1TKX5-G1TKX5_RABIT-AGRE5-Oryctolagus_cuniculus', \n",
    "    'F2': 'A0A452SUX4-A0A452SUX4_URSAM-AGRF2-Ursus_americanus', \n",
    "    'F4': 'W5PQ70-W5PQ70_SHEEP-AGRF4-Ovis_aries', \n",
    "    'G7': 'A0A2K5Y1I7-A0A2K5Y1I7_MANLE-AGRG7-Mandrillus_leucophaeus', \n",
    "    'L': 'A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii', \n",
    "    'L4': 'A0A7L3KTA8-A0A7L3KTA8_9PASS-AGRL4protein-Drymodes_brunneopygia.',\n",
    "    'V': 'A0A6Q2XYK2-A0A6Q2XYK2_ESOLU-AGRV1-Esox_lucius'\n",
    "    }\n",
    "\n",
    "target_folder = '../r2_template_pdbs/'\n",
    "for t_id in templates.keys():\n",
    "    print(t_id)\n",
    "    print(templates[t_id])\n",
    "    t_pdb = find_pdb(templates[t_id].split(\"-\")[0], '../all_pdbs/')\n",
    "    print(t_pdb)\n",
    "    # Find the template in the valid_collection\n",
    "    for gain in valid_collection.collection:\n",
    "        if gain.name.split(\"-\")[0] == templates[t_id].split(\"-\")[0]:\n",
    "            print(tf.get_pdb_extents(t_pdb, gain.subdomain_boundary))\n",
    "            \n",
    "            with open(t_pdb) as inpdb:\n",
    "                data = inpdb.readlines()\n",
    "            newdata = []\n",
    "            for l in data:\n",
    "                if not l.startswith(\"ATOM\"):\n",
    "                    newdata.append(l)\n",
    "                    continue\n",
    "                resid = int(l[22:26])\n",
    "                if \"b\" in t_id and resid < gain.subdomain_boundary:\n",
    "                    continue\n",
    "                if \"b\" not in t_id and resid > gain.subdomain_boundary:\n",
    "                    continue\n",
    "                newdata.append(l)\n",
    "            \n",
    "            with open(f\"{target_folder}{t_id}_{templates[t_id].split('-')[0]}.pdb\", \"w\") as outpdb:\n",
    "                outpdb.write(\"\".join(newdata))\n",
    "            \n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efcc3436bf700bf51081b251413b556e30c22be82f452601745119c8a669a2f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
