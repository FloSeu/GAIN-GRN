{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Notebook for Picking suitable Template Structures from Subgroups of the GAIN domain Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENCIES\n",
    "import glob, glob, re\n",
    "#from shutil import copyfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# LOCAL IMPORTS\n",
    "import sse_func\n",
    "import template_finder as tf\n",
    "\n",
    "#gesamt_bin = \"/home/hildilab/lib/xtal/ccp4-8.0/bin/gesamt\" #rk4\n",
    "gesamt_bin = \"/home/hildilab/lib/xtal/ccp4-8.0/ccp4-8.0/bin/gesamt\" #hildilab1a\n",
    "\n",
    "def calc_identity(aln_matrix):\n",
    "    # This takes an alignment matrix with shape=(n_columns, n_sequences) and generates counts based on the identity matrix.\n",
    "    # Returns the highest non \"-\" residue count as the most conserved residue and its occupancy based on count(\"-\") - n_struc\n",
    "    n_struc = aln_matrix.shape[0]\n",
    "    quality = []\n",
    "    occ = []\n",
    "    for col in range(aln_matrix.shape[1]):\n",
    "        chars, count = np.unique(aln_matrix[:,col], return_counts=True)\n",
    "        dtype = [('aa', 'S1'), ('counts', int)]\n",
    "        values = np.array(list(zip(chars,count)), dtype=dtype)\n",
    "        s_values = np.sort(values, order='counts')\n",
    "\n",
    "        if s_values[-1][0] == b'-':\n",
    "            q = s_values[-2][1]\n",
    "        else:\n",
    "            q = s_values[-1][1]\n",
    "        x = np.where(chars == '-')[0][0]\n",
    "        occ.append(n_struc - count[x])\n",
    "        quality.append(q)\n",
    "    return quality, occ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a remnant from the previous approach in having MSA-based anchors and is used as a comparative metric.\n",
    "valid_seqs = sse_func.read_multi_seq(\"/home/hildilab/projects/agpcr_nom/app_gain_gain.fa\")\n",
    "quality_file = \"/home/hildilab/projects/agpcr_nom/app_gain_gain.mafft.jal\"\n",
    "alignment_file = \"/home/hildilab/projects/agpcr_nom/app_gain_gain.mafft.fa\"\n",
    "stride_files = glob.glob(\"/home/hildilab/projects/agpcr_nom/sigmas/sigma_2_floats/*\")\n",
    "# This only contains the sigma files for truncated (?) PDBs.\n",
    "#quality = sse_func.read_quality(quality_file)\n",
    "gps_minus_one = 6781 \n",
    "aln_cutoff = 6826 \n",
    "alignment_dict = sse_func.read_alignment(alignment_file, aln_cutoff)\n",
    "aln_matrix = np.array([list(seq) for seq in alignment_dict.values()])\n",
    "#print(aln_matrix.shape)\n",
    "quality, occ = calc_identity(aln_matrix) # <-- This is a rough stacked residue Identity matrix to have the count of the most frequently occurring residue. \n",
    "\n",
    "precalc_anchors = [ 662, 1194, 1912, 2490, 2848, 3011, 3073, 3260, #H1-H8\n",
    "            3455, 3607, 3998, 4279, 4850, 5339, #5341 S1-S6, S7 REMOVED!\n",
    "            5413, 5813, 6337, 6659, 6696, 6765, 6808] #S8-13\n",
    "precalc_anchor_occupation = [ 4594.,  6539., 11392., 13658.,  8862., 5092.,  3228., 14189., #H1-H8\n",
    "                      9413., 12760.,  9420., 11201., 12283., 3676.,#  4562. S1-S6, S7 REMOVED!\n",
    "                     13992., 12575., 13999., 14051., 14353., 9760., 14215.] #S8-13\n",
    "precalc_anchor_dict = sse_func.make_anchor_dict(precalc_anchors, 3425)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, load the full GainCollection of the Dataset and habe the folder containing all GAIN PDB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_collection = pd.read_pickle(\"../valid_collection.p.pkl\")\n",
    "allpdbs = glob.glob('../all_pdbs/*.pdb')\n",
    "print(len(allpdbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk down the Dataset into Subselections containing every subfamily (\"A\", \"B\") and receptor type (\"B1\", \"D2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family(name):\n",
    "    # With the different namings, there is plenty of ambiguity regarding each aGPCR. This function mitigates this and posts A1,A2,....,V1 only from the protein name.\n",
    "    queries = [('AGR..', name, lambda x: x[-1][-2:]), #\n",
    "                ('ADGR..', name, lambda x: x[-1][-2:]), \n",
    "                ('cadher.*receptor.', name.lower(), lambda x: f\"C{x[-1][-1]}\"),\n",
    "                ('cels?r.', name.lower(), lambda x: f\"C{x[-1][-1]}\"), \n",
    "                ('latrophilin.*protein-?\\d', name.lower(), lambda x: f\"L{x[-1][-1]}\"),\n",
    "                ('latrophilin-?\\d', name.lower(), lambda x: f\"L{x[-1][-1]}\"),\n",
    "                ('GP?R133', name.upper(),lambda x: 'D1'),\n",
    "                ('GP?R126', name.upper(),lambda x: 'G6'),\n",
    "                ('GP?R?124', name.upper(),lambda x: 'A2'),\n",
    "                ('GP?R?125', name.upper(),lambda x: 'A3'),\n",
    "                ('GP?R112', name.upper(),lambda x: 'G4'),\n",
    "                ('GP?R116', name.upper(),lambda x: 'F5'),\n",
    "                ('GP?R144', name.upper(),lambda x: 'D2'),\n",
    "                ('ag-?.*-?coupled-?receptor-?.-?\\d', name.lower(),lambda x: x[-1].replace('-','')[-2:].upper()),\n",
    "                ('brain-?specific-?angiogenesis-?inhibitor-?\\d', name.lower(), lambda x: f\"B{x[-1][-1]}\"),\n",
    "                ('emr\\d', name.lower(), lambda x: f\"E{x[-1][-1]}\"),\n",
    "                ]\n",
    "    for pattern, searchstring, output in queries:\n",
    "        match = re.findall(pattern, searchstring)\n",
    "        if match != []:\n",
    "            #if output(match) == '': print(name)\n",
    "            return output(match)\n",
    "    return 'X'\n",
    "\n",
    "fam_list = [get_family(gain.name) for gain in v_collection.collection]\n",
    "name_list = [gain.name for gain in v_collection.collection]\n",
    "subfam_list = [x[0] for x in fam_list]\n",
    "print(fam_list)\n",
    "receptors, counts  = np.unique(fam_list, return_counts=True)\n",
    "r_list = list(zip(receptors,counts))\n",
    "print(r_list)\n",
    "print(receptors)\n",
    "fam_counts = {}\n",
    "for prot in fam_list:\n",
    "    fam = prot[0]\n",
    "    if fam not in fam_counts.keys():\n",
    "        fam_counts[fam] = 0\n",
    "    fam_counts[fam] += 1\n",
    "\n",
    "print(fam_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, the receptor groups to be tested are specified. The following sequence was tested:\n",
    "\n",
    "> - Run1: Subfamily-specific templates\n",
    "> - Run2: Added Receptor-specific templates for low-matching receptors\n",
    "> - Run3: Added further templates for extra 14th strand S4\n",
    "\n",
    "Every subselection is clustered via a pairwise RMSD-matrix constructed from individual _GESAMT_ runs. Two template candidates are then evaluated: The _overall_ centroid and the _largest cluster_ centroid. If they do not match, the clusters are evaluated to see whether there is are separate different clusters. A manual selection of the template is then carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Box is for running Subselections for Subdomain A >SDA<\n",
    "\n",
    "best_structures = {}\n",
    "best_clusters = {}\n",
    "\n",
    "#manual_receptors = [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\", \"E1\", \"E2\", \"E3\", \"E4\", \"E5\", \"F2\", \"F4\", \"F5\", \"D1\", \"L4\"]\n",
    "#manual_receptors = [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\", \"E1\", \"E2\", \"E3\", \"E4\", \"E5\", \"F2\", \"F4\", \"F5\", \"D1\", \"L4\"]\n",
    "manual_receptors = [\"G1\", \"G3\", \"G5\"]\n",
    "\n",
    "run_prefix = \"r4\"\n",
    "\n",
    "for r in manual_receptors:#'ABCDEFGLVX': #enumerate(receptors[:1])\n",
    "    print(r)\n",
    "    gain_subset = [ gain for i, gain in enumerate(v_collection.collection) if fam_list[i]==r ]#fam_list[i] == r]#\n",
    "    print(len(gain_subset))\n",
    "    gain_idx_list = [ i for i,gain in enumerate(fam_list) if gain == r ] # fam_list\n",
    "    maxlen = 400\n",
    "    data_length = len(gain_subset)\n",
    "    if data_length > maxlen:\n",
    "        data_length = maxlen # data_length will be used.\n",
    "        stride = data_length // maxlen\n",
    "        gain_subset = gain_subset[::stride]\n",
    "        gain_subset = gain_subset[:maxlen]\n",
    "        print(len(gain_idx_list), len(gain_subset))\n",
    "\n",
    "    gesamt_outfolder = f\"../{run_prefix}_gesamt_sda_adgr{r.lower()}\"\n",
    "    \n",
    "    tf.run_gesamt_execution(gain_subset, \n",
    "                            outfolder=gesamt_outfolder, \n",
    "                            pdb_folder='../all_pdbs', \n",
    "                            domain='sda', \n",
    "                            n_threads=6, \n",
    "                            max_struc=maxlen, \n",
    "                            gesamt_bin=gesamt_bin,\n",
    "                            no_run=False)\n",
    "    \n",
    "    distances = tf.evaluate_gesamt_files(gesamt_outfolder, n_prot=data_length, penalty_value=6.0, remove=False)\n",
    "    \n",
    "    print(distances.shape)\n",
    "    results = tf.cluster_agglomerative(distances, gain_subset, n_cluster=9)\n",
    "    tf.plot_heirarchy(results['reordered_distances'], groupname=f'ADGR{r}', savename=f'{run_prefix}_ADGR{r}_sda_heirarchy.png')\n",
    "    tf.plot_matrix(results['reordered_distances'], title=f'ADGR{r}', savename=f'{run_prefix}_ADGR{r}_sda_ordered_matrix.png')\n",
    "    #print(results.keys())\n",
    "    #print(results['overall_best_gain'], results['cluster_best_gains'])\n",
    "    all_best = gain_subset[results['overall_best_gain']].name\n",
    "    best_list = []\n",
    "    for i, c in results['cluster_best_gains']:\n",
    "        best_list.append((gain_subset[i].name, c, results['cluster_sizes'][c]))\n",
    "    best_structures[r] = all_best\n",
    "    best_clusters[r] = best_list\n",
    "    print(\"Done with run\",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Box is for running Subselections for Subdomain B >SDB<\n",
    "best_structures = {}\n",
    "best_clusters = {}\n",
    "\n",
    "#manual_receptors = [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\", \"E1\", \"E2\", \"E3\", \"E4\", \"E5\", \"F2\", \"F4\", \"F5\", \"D1\", \"L4\"]\n",
    "manual_receptors = [\"G2\", \"G4\", \"G6\", \"G7\", \"A2\", \"A3\"]\n",
    "\n",
    "for r in manual_receptors:#'ABCDEFGLVX': #enumerate(receptors[:1])\n",
    "    print(r)\n",
    "    gain_subset = [ gain for i, gain in enumerate(v_collection.collection) if fam_list[i]==r ]#fam_list[i] == r]#\n",
    "    print(len(gain_subset))\n",
    "    gain_idx_list = [ i for i,gain in enumerate(fam_list) if gain == r ] # fam_list\n",
    "    maxlen = 400\n",
    "    data_length = len(gain_subset)\n",
    "    if data_length > maxlen:\n",
    "        data_length = maxlen # data_length will be used.\n",
    "        stride = data_length // maxlen\n",
    "        gain_subset = gain_subset[::stride]\n",
    "        gain_subset = gain_subset[:maxlen]\n",
    "        print(len(gain_idx_list), len(gain_subset))\n",
    "\n",
    "    gesamt_outfolder = f\"../r3_gesamt_sdb_adgr{r.lower()}\"\n",
    "    \n",
    "    tf.run_gesamt_execution(gain_subset, outfolder=gesamt_outfolder, gesamt_bin=gesamt_bin, pdb_folder='../all_pdbs', domain='sdb', n_threads=20, max_struc=maxlen, no_run=False)\n",
    "    distances = tf.evaluate_gesamt_files(gesamt_outfolder, n_prot=data_length, penalty_value=6.0, remove=False)\n",
    "    print(distances.shape)\n",
    "    results = tf.cluster_agglomerative(distances, gain_subset, n_cluster=9)\n",
    "    tf.plot_heirarchy(results['reordered_distances'], groupname=f'ADGR{r}', savename=f'../r3_ADGR{r}_sdb_heirarchy.png')\n",
    "    tf.plot_matrix(results['reordered_distances'], title=f'ADGR{r}', savename=f'../r3_ADGR{r}_sdb_ordered_matrix.png')\n",
    "    #print(results.keys())\n",
    "    #print(results['overall_best_gain'], results['cluster_best_gains'])\n",
    "    all_best = gain_subset[results['overall_best_gain']].name\n",
    "    best_list = []\n",
    "    for i, c in results['cluster_best_gains']:\n",
    "        best_list.append((gain_subset[i].name, c, results['cluster_sizes'][c]))\n",
    "    best_structures[r] = all_best\n",
    "    best_clusters[r] = best_list\n",
    "    print(\"Done with run\",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_structures)\n",
    "print(best_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After creating a set of potential templates, they will each be evaluated against the whole set to remove arbitrarily similar templates, since not every receptor needs a unique template if they are too similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "# Run 1\n",
    "\"\"\"best_sda = {'A':'A0A6G1Q0B9-A0A6G1Q0B9_9TELE-AGRA2-Channa_argus', \n",
    "            REMOVE'B':'A0A3Q2EII6-A0A3Q2EII6_CYPVA-AGRB3-Cyprinodon_variegatus', \n",
    "            'C':'A0A6J2Q002-A0A6J2Q002_COTGO-cadherinEGFLAGseven-passG-typereceptor3-Cottoperca_gobio',\n",
    "            'D':'A0A3B4GU56-A0A3B4GU56_9CICH-AGRD1-Pundamilia_nyererei.',\n",
    "            REMOVE'E':'A0A452F289-A0A452F289_CAPHI-AGRE2-Capra_hircus',\n",
    "            'F':'A0A3Q2GWY2-A0A3Q2GWY2_HORSE-AGRF5-Equus_caballus',\n",
    "            REMOVE'G':'A0A7K4YYI3-A0A7K4YYI3_BUCAB-AGRG6protein-Bucorvus_abyssinicus',\n",
    "            'L':'A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii',\n",
    "            'V':'A0A2R9B651-A0A2R9B651_PANPA-AGRV1-Pan_paniscus',\n",
    "            'X':'A0A674N8V9-A0A674N8V9_TAKRU-Uncharacterizedprotein-Takifugu_rubripes',\n",
    "            }\"\"\"\n",
    "\n",
    "# Detailed Run 2\n",
    "best_sda = {'G1': 'A0A7L3GD10-A0A7L3GD10_9AVES-AGRG1-Anhinga_rufa', \n",
    "'G2': 'A0A2K5MG19-A0A2K5MG19_CERAT-AGRG2-Cercocebus_atys', \n",
    "'G3': 'A0A3Q7QGV6-A0A3Q7QGV6_CALUR-AGRG3-likeisoformX3-Callorhinus_ursinus', \n",
    "'G4': 'A0A2I4CCH8-A0A2I4CCH8_9TELE-AGRG4-like-Austrofundulus_limnaeus.', \n",
    "'G5': 'A0A6J3IBI5-A0A6J3IBI5_SAPAP-AGRG5-Sapajus_apella', \n",
    "'G6': 'A0A6P7HB06-A0A6P7HB06_9TELE-AGRG6isoformX6-Parambassis_ranga', \n",
    "#'G6.1': 'F6QI92-F6QI92_CALJA-AGRG6-Callithrix_jacchus', \n",
    "#'G6.2':'A0A7J7WUN2-A0A7J7WUN2_MYOMY-AGRG6-Myotis_myotis',\n",
    "'G7': 'A0A2K5Y1I7-A0A2K5Y1I7_MANLE-AGRG7-Mandrillus_leucophaeus', \n",
    "'E1': 'A0A2I2YJG7-A0A2I2YJG7_GORGO-AGRE1-Gorilla_gorilla_gorilla', \n",
    "'E2': 'A0A2Y9QG39-A0A2Y9QG39_TRIMA-AGRE2isoformX3-Trichechus_manatus_latirostris', \n",
    "'E3': 'A0A2Y9M464-A0A2Y9M464_DELLE-AGRE3isoformX1-Delphinapterus_leucas', \n",
    "'E4': 'A0A6J3FRL0-A0A6J3FRL0_SAPAP-putativeAGRE4PisoformX1-Sapajus_apella', \n",
    "'E5': 'G1TKX5-G1TKX5_RABIT-AGRE5-Oryctolagus_cuniculus', \n",
    "#'E5.1': 'A0A2R9CT02-A0A2R9CT02_PANPA-AGRE5-Pan_paniscus',\n",
    "#'E5.2': 'F6PLI2-F6PLI2_CANLF-AGRE5-Canis_lupus_familiaris',\n",
    "'F2': 'A0A452SUX4-A0A452SUX4_URSAM-AGRF2-Ursus_americanus', \n",
    "#'F2.1':'A0A3Q0CU45-A0A3Q0CU45_MESAU-AGRF2-Mesocricetus_auratus',  \n",
    "#'F2.2':'E2RAG2-E2RAG2_CANLF-AGRF2-Canis_lupus_familiaris',\n",
    "'F4': 'W5PQ70-W5PQ70_SHEEP-AGRF4-Ovis_aries', \n",
    "'F5': 'A0A7L3N0A5-A0A7L3N0A5_9AVES-AGRF5protein-Oreotrochilus_melanogaster.', \n",
    "#'F5.1':'A0A1U7SCS2-A0A1U7SCS2_ALLSI-AGRF5isoformX1-Alligator_sinensis',\n",
    "#'F5.2':'A0A7K5GSD3-A0A7K5GSD3_9AVES-AGRF5protein-Chunga_burmeisteri',\n",
    "'D1': 'A0A369SLT5-A0A369SLT5_9METZ-AGRD1-Trichoplax_sp._H2.', \n",
    "'L4': 'A0A7L3KTA8-A0A7L3KTA8_9PASS-AGRL4protein-Drymodes_brunneopygia.'}\n",
    "#\n",
    "# os.mkdir('../sda_templates/')\n",
    "#for f,p in best_sda.items():\n",
    "#    ident = p.split(\"-\")[0]\n",
    "#    pdb = [x for x in allpdbs if ident in x][0]\n",
    "#    shutil.copyfile(pdb, f'../r2_sda_templates/ADGR{f}_sda_{pdb.split(\"/\")[-1]}')\n",
    "\n",
    "# Run 3 SDB templates\n",
    "best_sdb = {\n",
    "'A3': 'A0A093HFD2', #!\n",
    "'A2': 'A0A7N6BTD2', #=\n",
    "'G7': 'A0A2K5Y1I7', #=\n",
    "'G6': 'F6QI92',     #!\n",
    "'G4': 'A0A2I4CCH8', #=\n",
    "'G2': 'A0A2K5MG19'  #=\n",
    "}\n",
    "\n",
    "os.mkdir('../r3_sdb_templates/')\n",
    "for f,p in best_sdb.items():\n",
    "    ident = p.split(\"-\")[0]\n",
    "    pdb = [x for x in allpdbs if ident in x][0]\n",
    "    shutil.copyfile(pdb, f'../r3_sdb_templates/ADGR{f}_sda_{pdb.split(\"/\")[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy other template files here\n",
    "\n",
    "import glob,shutil\n",
    "#       entry name                                              cluster_id  n_structures of cluster\n",
    "x = [\n",
    "    ('A0A1U7SCS2-A0A1U7SCS2_ALLSI-AGRF5isoformX1-Alligator_sinensis', 0, 150), \n",
    "    ('A0A7K5GSD3-A0A7K5GSD3_9AVES-AGRF5protein-Chunga_burmeisteri', 6, 169),\n",
    "    ('A0A3Q0CU45-A0A3Q0CU45_MESAU-AGRF2-Mesocricetus_auratus', 1, 50), \n",
    "    ('E2RAG2-E2RAG2_CANLF-AGRF2-Canis_lupus_familiaris', 2, 38),\n",
    "    ('A0A2R9CT02-A0A2R9CT02_PANPA-AGRE5-Pan_paniscus', 0, 51), \n",
    "    ('F6PLI2-F6PLI2_CANLF-AGRE5-Canis_lupus_familiaris', 1, 53), \n",
    "    ('A0A337S7C5-A0A337S7C5_FELCA-AGRE1-Felis_catus', 6, 181),\n",
    "    ('F6QI92-F6QI92_CALJA-AGRG6-Callithrix_jacchus', 0, 220),\n",
    "    ('A0A7J7WUN2-A0A7J7WUN2_MYOMY-AGRG6-Myotis_myotis', 2, 170)\n",
    "    ]\n",
    "x = ['A0A3Q7VNP9-A0A3Q7VNP9_URSAR-AGRG3isoformX1-Ursus_arctos_horribilis.',\n",
    "'A0A6J0YEE1-A0A6J0YEE1_ODOVR-AGRG3-Odocoileus_virginianus_texanus.',\n",
    "'A0A3Q7W7P5-A0A3Q7W7P5_URSAR-AGRG3isoformX2-Ursus_arctos_horribilis.',\n",
    "'U3JWQ8-U3JWQ8_FICAL-AGRG3-Ficedula_albicollis',\n",
    "'A0A6J2EWP7-A0A6J2EWP7_ZALCA-AGRG3isoformX2-Zalophus_californianus',\n",
    "'A0A3Q7QGV6-A0A3Q7QGV6_CALUR-AGRG3-likeisoformX3-Callorhinus_ursinus',\n",
    "'A0A4U5U610-A0A4U5U610_COLLU-AGRG3GR97-Collichthys_lucidus',\n",
    "'A0A671ED21-A0A671ED21_RHIFE-AGRG3-Rhinolophus_ferrumequinum',\n",
    "'A0A673W4X1-A0A673W4X1_SALTR-AGRG3-like-Salmo_trutta']\n",
    "allpdbs = glob.glob('../all_pdbs/*.pdb')\n",
    "for i,t in enumerate(x): \n",
    "    ident = t.split(\"-\")[0]\n",
    "    pdb = [x for x in allpdbs if ident in x][0]\n",
    "    shutil.copyfile(pdb, f'../r2_sda_templates/G3sp_sda_{pdb.split(\"/\")[-1]}_{t.split(\"AGR\")[1][:2]}.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 1 templates for SDA\n",
    "y = {'A': 'A0A2Y9F628-A0A2Y9F628_PHYMC-AGRA3isoformX1-Physeter_macrocephalus', \n",
    "'B': 'A0A4W6DVA0-A0A4W6DVA0_LATCA-AGRB1b-Lates_calcarifer', \n",
    "'C': 'A0A7K6E127-A0A7K6E127_9PASS-CELR3protein-Grantiella_picta.', \n",
    "'D': 'I3M3G4-I3M3G4_ICTTR-AGRD1-Ictidomys_tridecemlineatus', \n",
    "'E': 'A0A3P8S994-A0A3P8S994_AMPPE-AGRE5b,duplicate2-Amphiprion_percula', \n",
    "'F': 'A0A452IH20-A0A452IH20_9SAUR-AGRF5-Gopherus_agassizii', \n",
    "'G': 'A0A7K5TKG3-A0A7K5TKG3_9FRIN-AGRG6protein-Urocynchramus_pylzowi.', \n",
    "'L': 'A0A452HCU9-A0A452HCU9_9SAUR-AGRL3-Gopherus_agassizii', \n",
    "'X': \"A0A6F9A857-A0A6F9A857_9TELE-Uncharacterizedprotein-Coregonus_sp._'balchen'.\", \n",
    "'V': 'A0A6Q2XYK2-A0A6Q2XYK2_ESOLU-AGRV1-Esox_lucius'}\n",
    "\n",
    "#os.mkdir(\"../sdb_templates\")\n",
    "for f,a in y.items():\n",
    "    print(f,a)\n",
    "    ident = a.split(\"-\")[0]\n",
    "    pdb = [x for x in allpdbs if ident in x][0]\n",
    "    print(ident, pdb)\n",
    "    shutil.copyfile(pdb, f'../sdb_templates/{f}_sdb_{pdb.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results.keys())\n",
    "#print(results['overall_best_gain'], results['cluster_best_gains'])\n",
    "all_best = gain_subset[results['overall_best_gain']].name\n",
    "best_list = []\n",
    "for i, c in results['cluster_best_gains']:\n",
    "    best_list.append((gain_subset[i].name, c, results['cluster_sizes'][c]))\n",
    "print(all_best)\n",
    "print(best_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the directories with the potential templates have been created, we proceed to __template_testing.ipynb__ to evaluate them and select our final set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efcc3436bf700bf51081b251413b556e30c22be82f452601745119c8a669a2f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
