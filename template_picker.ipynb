{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Notebook for Picking suitable Template Structures from Subgroups of the GAIN domain Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENCIES\n",
    "import glob, glob, re\n",
    "#from shutil import copyfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# LOCAL IMPORTS\n",
    "import sse_func\n",
    "import template_finder as tf\n",
    "\n",
    "gesamt_bin = \"/home/hildilab/lib/xtal/ccp4-8.0/ccp4-8.0/bin/gesamt\" #specify the location of your GESAMT executable\n",
    "\n",
    "def calc_identity(aln_matrix):\n",
    "    # This takes an alignment matrix with shape=(n_columns, n_sequences) and generates counts based on the identity matrix.\n",
    "    # Returns the highest non \"-\" residue count as the most conserved residue and its occupancy based on count(\"-\") - n_struc\n",
    "    n_struc = aln_matrix.shape[0]\n",
    "    quality = []\n",
    "    occ = []\n",
    "    for col in range(aln_matrix.shape[1]):\n",
    "        chars, count = np.unique(aln_matrix[:,col], return_counts=True)\n",
    "        dtype = [('aa', 'S1'), ('counts', int)]\n",
    "        values = np.array(list(zip(chars,count)), dtype=dtype)\n",
    "        s_values = np.sort(values, order='counts')\n",
    "\n",
    "        if s_values[-1][0] == b'-':\n",
    "            q = s_values[-2][1]\n",
    "        else:\n",
    "            q = s_values[-1][1]\n",
    "        x = np.where(chars == '-')[0][0]\n",
    "        occ.append(n_struc - count[x])\n",
    "        quality.append(q)\n",
    "    return quality, occ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a remnant from the previous approach in having MSA-based anchors and is used as a comparative metric.\n",
    "valid_seqs = sse_func.read_multi_seq(\"../agpcr_celsr.fa\")\n",
    "stride_files = glob.glob(\"../sigma_2_floats/*.stride\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, load the full GainCollection of the Dataset and habe the folder containing all GAIN PDB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_collection = pd.read_pickle(\"../valid_collection.q.pkl\")\n",
    "allpdbs = glob.glob('../all_pdbs/*.pdb')\n",
    "print(len(allpdbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk down the Dataset into Subselections containing every subfamily (\"A\", \"B\") and receptor type (\"B1\", \"D2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family(name):\n",
    "    # With the different namings, there is plenty of ambiguity regarding each aGPCR. This function mitigates this and posts A1,A2,....,V1 only from the protein name.\n",
    "    queries = [('AGR..', name, lambda x: x[-1][-2:]), #\n",
    "                ('ADGR..', name, lambda x: x[-1][-2:]), \n",
    "                ('cadher.*receptor.', name.lower(), lambda x: f\"C{x[-1][-1]}\"),\n",
    "                ('cels?r.', name.lower(), lambda x: f\"C{x[-1][-1]}\"), \n",
    "                ('latrophilin.*protein-?\\d', name.lower(), lambda x: f\"L{x[-1][-1]}\"),\n",
    "                ('latrophilin-?\\d', name.lower(), lambda x: f\"L{x[-1][-1]}\"),\n",
    "                ('GP?R133', name.upper(),lambda x: 'D1'),\n",
    "                ('GP?R126', name.upper(),lambda x: 'G6'),\n",
    "                ('GP?R?124', name.upper(),lambda x: 'A2'),\n",
    "                ('GP?R?125', name.upper(),lambda x: 'A3'),\n",
    "                ('GP?R112', name.upper(),lambda x: 'G4'),\n",
    "                ('GP?R116', name.upper(),lambda x: 'F5'),\n",
    "                ('GP?R144', name.upper(),lambda x: 'D2'),\n",
    "                ('ag-?.*-?coupled-?receptor-?.-?\\d', name.lower(),lambda x: x[-1].replace('-','')[-2:].upper()),\n",
    "                ('brain-?specific-?angiogenesis-?inhibitor-?\\d', name.lower(), lambda x: f\"B{x[-1][-1]}\"),\n",
    "                ('emr\\d', name.lower(), lambda x: f\"E{x[-1][-1]}\"),\n",
    "                ]\n",
    "    for pattern, searchstring, output in queries:\n",
    "        match = re.findall(pattern, searchstring)\n",
    "        if match != []:\n",
    "            #if output(match) == '': print(name)\n",
    "            return output(match)\n",
    "    return 'X'\n",
    "\n",
    "fam_list = [get_family(gain.name) for gain in v_collection.collection]\n",
    "name_list = [gain.name for gain in v_collection.collection]\n",
    "subfam_list = [x[0] for x in fam_list]\n",
    "print(fam_list)\n",
    "receptors, counts  = np.unique(fam_list, return_counts=True)\n",
    "r_list = list(zip(receptors,counts))\n",
    "print(r_list)\n",
    "print(receptors)\n",
    "fam_counts = {}\n",
    "for prot in fam_list:\n",
    "    fam = prot[0]\n",
    "    if fam not in fam_counts.keys():\n",
    "        fam_counts[fam] = 0\n",
    "    fam_counts[fam] += 1\n",
    "\n",
    "print(fam_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, the receptor groups to be tested are specified. The following sequence was tested:\n",
    "\n",
    "> - Run1: Subfamily-specific templates\n",
    "> - Run2: Added Receptor-specific templates for low-matching receptors\n",
    "> - Run3: Added further templates for extra 14th strand S4\n",
    "\n",
    "Every subselection is clustered via a pairwise RMSD-matrix constructed from individual _GESAMT_ runs. Two template candidates are then evaluated: The _overall_ centroid and the _largest cluster_ centroid. If they do not match, the clusters are evaluated to see whether there is are separate different clusters. A manual selection of the template is then carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Box is for running Subselections for Subdomain A >SDA<\n",
    "\n",
    "best_structures = {}\n",
    "best_clusters = {}\n",
    "\n",
    "manual_receptors = [\"X\"]\n",
    "\n",
    "run_prefix = \"p1\"\n",
    "print(allpdbs)\n",
    "gain_subset = v_collection.collection\n",
    "print(len(gain_subset))\n",
    "\n",
    "gain_idx_list = range(len(fam_list)) # fam_list\n",
    "maxlen = 400\n",
    "data_length = len(gain_subset)\n",
    "if data_length > maxlen:\n",
    "    data_length = maxlen # data_length will be used.\n",
    "    stride = data_length // maxlen\n",
    "    gain_subset = gain_subset[::stride]\n",
    "    gain_subset = gain_subset[:maxlen]\n",
    "    print(len(gain_idx_list), len(gain_subset))\n",
    "\n",
    "gesamt_outfolder = f\"../{run_prefix}_gesamt_sda_pc\"\n",
    "\n",
    "tf.run_gesamt_execution(gain_subset, \n",
    "                        outfolder=gesamt_outfolder, \n",
    "                        pdb_folder='../all_pdbs/', \n",
    "                        domain='sda', \n",
    "                        n_threads=4, \n",
    "                        max_struc=maxlen, \n",
    "                        gesamt_bin=gesamt_bin,\n",
    "                        no_run=False)\n",
    "distances = tf.evaluate_gesamt_files(gesamt_outfolder, n_prot=data_length, penalty_value=6.0, remove=False)\n",
    "\n",
    "print(distances.shape)\n",
    "results = tf.cluster_agglomerative(distances, gain_subset, n_cluster=9)\n",
    "tf.plot_heirarchy(results['reordered_distances'], groupname=f'aGPCR GAIN', savename=f'{run_prefix}_A_sda_heirarchy.png')\n",
    "tf.plot_matrix(results['reordered_distances'], title=f'aGPCR GAIN', savename=f'{run_prefix}_sda_ordered_matrix.png')\n",
    "#print(results.keys())\n",
    "#print(results['overall_best_gain'], results['cluster_best_gains'])\n",
    "all_best = gain_subset[results['overall_best_gain']].name\n",
    "best_list = []\n",
    "for i, c in results['cluster_best_gains']:\n",
    "    best_list.append((gain_subset[i].name, c, results['cluster_sizes'][c]))\n",
    "best_structures[r] = all_best\n",
    "best_clusters[r] = best_list\n",
    "print(\"Done with run\",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Box is for running Subselections for Subdomain B >SDB<\n",
    "best_structures = {}\n",
    "best_clusters = {}\n",
    "\n",
    "for r in 'ABCDEFGLVX': #enumerate(receptors[:1])\n",
    "    print(r)\n",
    "    gain_subset = [ gain for i, gain in enumerate(v_collection.collection) if fam_list[i]==r ]#fam_list[i] == r]#\n",
    "    print(len(gain_subset))\n",
    "    gain_idx_list = [ i for i,gain in enumerate(fam_list) if gain == r ] # fam_list\n",
    "    maxlen = 400\n",
    "    data_length = len(gain_subset)\n",
    "    if data_length > maxlen:\n",
    "        data_length = maxlen # data_length will be used.\n",
    "        stride = data_length // maxlen\n",
    "        gain_subset = gain_subset[::stride]\n",
    "        gain_subset = gain_subset[:maxlen]\n",
    "        print(len(gain_idx_list), len(gain_subset))\n",
    "\n",
    "    gesamt_outfolder = f\"../{run_prefix}_gesamt_sdb_pc\"\n",
    "    \n",
    "    tf.run_gesamt_execution(gain_subset, outfolder=gesamt_outfolder, gesamt_bin=gesamt_bin, pdb_folder='../all_pdbs/', domain='sdb', n_threads=4, max_struc=maxlen, no_run=False)\n",
    "    distances = tf.evaluate_gesamt_files(gesamt_outfolder, n_prot=data_length, penalty_value=6.0, remove=False)\n",
    "    print(distances.shape)\n",
    "    results = tf.cluster_agglomerative(distances, gain_subset, n_cluster=9)\n",
    "    tf.plot_heirarchy(results['reordered_distances'], groupname=f'aGPCR GAIN', savename=f'{run_prefix}_sdb_heirarchy.png')\n",
    "    tf.plot_matrix(results['reordered_distances'], title=f'aGPCR GAIN', savename=f'{run_prefix}_sdb_ordered_matrix.png')\n",
    "    #print(results.keys())\n",
    "    #print(results['overall_best_gain'], results['cluster_best_gains'])\n",
    "    all_best = gain_subset[results['overall_best_gain']].name\n",
    "    best_list = []\n",
    "    for i, c in results['cluster_best_gains']:\n",
    "        best_list.append((gain_subset[i].name, c, results['cluster_sizes'][c]))\n",
    "    best_structures[r] = all_best\n",
    "    best_clusters[r] = best_list\n",
    "    print(\"Done with run\",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_structures)\n",
    "print(best_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After creating a set of potential templates, they will each be evaluated against the whole set to remove arbitrarily similar templates, since not every receptor needs a unique template if they are too similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results.keys())\n",
    "#print(results['overall_best_gain'], results['cluster_best_gains'])\n",
    "all_best = gain_subset[results['overall_best_gain']].name\n",
    "best_list = []\n",
    "for i, c in results['cluster_best_gains']:\n",
    "    best_list.append((gain_subset[i].name, c, results['cluster_sizes'][c]))\n",
    "print(all_best)\n",
    "print(best_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the directories with the potential templates have been created, we proceed to __template_testing.ipynb__ to evaluate them and select our final set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efcc3436bf700bf51081b251413b556e30c22be82f452601745119c8a669a2f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
