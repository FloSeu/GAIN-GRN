{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: a collection of GAIN domain PDBs, their sequences as one large \".fa\" file\n",
    "from gain_classes import GainDomain, GainCollection, Anchors, GPS\n",
    "import sse_func\n",
    "import execute\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from shutil import copyfile\n",
    "import math\n",
    "import re\n",
    "\n",
    "valid_seqs = sse_func.read_multi_seq(\"/home/hildilab/projects/agpcr_nom/app_gain_gain.fa\")\n",
    "quality_file = \"/home/hildilab/projects/agpcr_nom/app_gain_gain.mafft.jal\"\n",
    "alignment_file = \"/home/hildilab/projects/agpcr_nom/app_gain_gain.mafft.fa\"\n",
    "stride_files = glob.glob(\"/home/hildilab/projects/agpcr_nom/sigmas/sigma_2/*\")\n",
    "# This only contains the sigma files for truncated (?) PDBs.\n",
    "quality = sse_func.read_quality(quality_file)\n",
    "gps_minus_one = 6781 \n",
    "aln_cutoff = 6826 \n",
    "alignment_dict = sse_func.read_alignment(alignment_file, aln_cutoff)\n",
    "\n",
    "# Pre-calculated Anchor data.\n",
    "\"\"\"anchors = [ 662, 1194, 1912, 2490, 2848, 3011, 3073, 3260, 3455, 3607, 3998, 4279, 4850, 5339, 5341, 5413, 5813, 6337, 6659, 6696, 6765, 6808 ] \n",
    "\n",
    "anchor_occupation = [ 4594.0,  6539.0, 11392.0, 13658.0,  8862.0,  5092.0,  3228.0, 14189.0,  \n",
    "\t\t\t\t\t  9413.0, 12760.0, 9420.0, 11201.0, 12283.0,  3676.0,  4562.0, 13992.0, \n",
    "\t\t\t\t\t  12575.0, 13999.0, 14051.0, 14353.0, 9760.0, 14215.0]\"\"\"\n",
    "sdb = 3425\n",
    "# ADJUSTED ANCHORS!\n",
    "anchors = [ 662, 1194, 1912, 2490, 2848, 3011, 3073, 3260, 3455, 3607, 3998, 4279, 4850, 5339,\n",
    " 5413, 5813, 6337, 6659, 6696, 6765, 6808] # removed S7 @  5341\n",
    "anchor_occupation = [ 4594.,  6539., 11392., 13658.,  8862., 5092.,  3228., 14189.,  9413., 12760.,\n",
    "  9420., 11201., 12283.,  3676.,   13992., 12575., 13999., 14051., 14353., 9760., 14215.] # removed S7 @ 4562.,\n",
    "\n",
    "anchor_dict = sse_func.make_anchor_dict(anchors, sdb) # 3425 is the subdomain boundary in the GAIN alignment\n",
    "print(anchor_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for the integration of invertebrate receptors into the existing GAIN GRN. These receptors (and other low-homology GAIN-containing proteins) have homology too low to be tackled by MAFFT and therefore we need a separate workflow for their integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pw_alignment(alnfile):\n",
    "    \"\"\" Reads *.aln file from AlignMe, returns the double string [\"XXXXX\", \"XXXXX\"] where both are the alignment-wise sequences of chars\"\"\"\n",
    "    with open(alnfile) as f:\n",
    "        data = [ l.strip() for l in f.readlines() if len(l.strip()) > 4 ]\n",
    "        print(f\"[DEBUG] {len(data) = }\")\n",
    "    seq_dict = {}\n",
    "    for l in data[1:]: # omit header.\n",
    "        \n",
    "        seq_name, string_block = l.split()\n",
    "        \n",
    "        if seq_name not in seq_dict.keys():\n",
    "            seq_dict[seq_name] = string_block\n",
    "            continue\n",
    "\n",
    "        seq_dict[seq_name] += string_block\n",
    "\n",
    "    return seq_dict\n",
    "\n",
    "def map_pw_alignment(aln_dict, template_seq, target_seq, template_id):\n",
    "    \"\"\" Maps two sequences from the target alignment onto one another, returns a matrix where the target sequence matches the template. \"\"\"\n",
    "    template_key = [k for k in aln_dict.keys() if template_id in k][0]\n",
    "    template_aln_string = aln_dict[template_key]\n",
    "    target_key = [k for k in aln_dict.keys() if template_id not in k][0]\n",
    "    target_aln_string = aln_dict[target_key]\n",
    "\n",
    "    current_col = 0\n",
    "    current_template_res = 0\n",
    "    mapper = np.empty((len(target_seq)))\n",
    "    mapper.fill(None)\n",
    "\n",
    "    # transform the template_aln_string to a set of numbers corresponding to resnum of template\n",
    "    template_num = np.empty((len(template_aln_string)))\n",
    "    template_num.fill(None)\n",
    "    resnum = 0\n",
    "    for idx, char in enumerate(template_aln_string):\n",
    "        if char == \"-\": continue\n",
    "        template_num[idx] = resnum\n",
    "        resnum += 1\n",
    "\n",
    "    # With target_seq, find the mapped residue numbers in the aligned target_aln_string\n",
    "    for idx, char in enumerate(target_seq):\n",
    "        \n",
    "        while target_aln_string[current_col] == \"-\":   # Skip \"-\" characters\n",
    "            current_col += 1\n",
    "\n",
    "        if target_aln_string[current_col] == char:\n",
    "            mapper[idx] = template_num[current_col] # Write in the residue number from the mapped template_num\n",
    "        else:\n",
    "            print(\"Character MISMATCH!\", target_aln_string[current_col],\"vs.\", char)\n",
    "        current_col += 1\n",
    "    return mapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADGRD1 is our reference Domain. Any Anchors present in this domain will be assigned to profile-matched GAINs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Q6QNK2_B2CKK9_B7ZLF7_Q2M1L3_Q6ZMQ1_Q7Z7M2_Q86SM4-AGRD1_HUMAN-AGRD1-Homo_sapiens' \n",
    "seq = 'TPDEIAMYFTAAIGKHALLSSTLPSLFMTSTASPVMPTDAYHPIITNLTEERKTFQSPGVILSYLQNVSLSLPSKSLSEQTALNLTKTFLKAVGEILLLPGWIALSEDSAVVLSLIDTIDTVMGHVSSNLHGSTPQVTVEGSSAMAEFSVAKILPKTVNSSHYRFPAHGQSFIQIPHEAFHRHAWSTVVGLLYHSMHYYLNNIWPAHTKIAEAMHHQDCLLFATSHLISLEVSPPPTLSQNLSGSPLITVHLKHRLTRKQHSEATNSSNRVFVYCAFLDFSSGEGVWSNHGCALTRGNLTYSVCRCTHLTNFAILMQVVPL'\n",
    "d1_stride = \"/home/hildilab/projects/agpcr_nom/all_gps_stride/Q6QNK2_B2CKK9_B7ZLF7_Q2M1L3_Q6ZMQ1_Q7Z7M2_Q86SM4-AGRD1_HUMAN-AGRD1-Homo_sapiens.stride\"\n",
    "d1_gain = GainDomain(alignment_file = alignment_file,\n",
    "                                        aln_cutoff = aln_cutoff,\n",
    "                                        quality = quality,\n",
    "                                        gps_index = gps_minus_one,\n",
    "                                        name = name,\n",
    "                                        sequence = seq,\n",
    "                                        alignment_dict = alignment_dict,\n",
    "                                        explicit_stride_file=d1_stride,\n",
    "                                        is_truncated = True,\n",
    "                                        stride_outlier_mode = True,\n",
    "                                        without_anchors=False)\n",
    "#d1_gain.plot_helicality()\n",
    "print(d1_gain.subdomain_boundary, d1_gain.start, d1_gain.end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_gain.alignment_indices\n",
    "invertebrate_proteins = [f for f in glob.glob(\"/home/hildilab/projects/GPS_massif/invert_truncs/alignme/aln/*\") if \"zip\" not in f]\n",
    "\n",
    "xdir = invertebrate_proteins[0]\n",
    "\n",
    "alnfile = glob.glob(f\"{xdir}/*aln\")[0]\n",
    "target_name, target_seq = sse_func.read_seq(glob.glob(f\"{xdir}/fasta2*\")[0], return_name=True)\n",
    "print(glob.glob(f\"{xdir}/fasta2*\")[0])\n",
    "print(target_name, target_seq)\n",
    "aln_dict = read_pw_alignment(alnfile)\n",
    "mapper = map_pw_alignment(aln_dict, template_seq=seq, target_seq=target_seq, template_id=\"Q6QNK2\")\n",
    "# this mapper is zero_indexed.\n",
    "#print(mapper)\n",
    "\n",
    "# Build the target alignment columns from mapping the parwise matrix onto the respective template alignment indices\n",
    "tar_aln_cols = []\n",
    "for val in mapper:\n",
    "    if not math.isnan(val):\n",
    "        tar_aln_cols.append(d1_gain.alignment_indices[int(val)])\n",
    "\n",
    "#print(tar_aln_cols)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the extracted alignment columns, we can inherit the GAIN domain class to patch in the newly generated alignment indices and generate the indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrealignedGain(GainDomain):\n",
    "    # Overwrite the init function to incorporate the skipping of alignment-index generation\n",
    "    def __init__(self, \n",
    "                 alignment_file, \n",
    "                 aln_cutoff,\n",
    "                 quality,\n",
    "                 gps_index, \n",
    "                 alignment_indices,\n",
    "                 alignment_dict=None,\n",
    "                 fasta_file=None,\n",
    "                 name=None,\n",
    "                 sequence=None,\n",
    "                 subdomain_bracket_size=20,\n",
    "                 domain_threshold=20,\n",
    "                 coil_weight=0,\n",
    "                 explicit_stride_file=None,\n",
    "                 #without_anchors=False,\n",
    "                 is_truncated=True, # False\n",
    "                 skip_naming=False,\n",
    "                 stride_outlier_mode=False,\n",
    "                 truncation_map=None,\n",
    "                 aln_start_res=None):   \n",
    "        \n",
    "        #Initialize self.name for finding the correspondent alignment row!\n",
    "        if name is not None:\n",
    "            self.name = name\n",
    "        else:\n",
    "            if fasta_file:\n",
    "                self.name = fasta_file.split(\"/\")[-1] # This is how the name would be in the pre-calculated alignment\n",
    "            else:\n",
    "                print(\"No name specified. Exiting\")\n",
    "                return None\n",
    "\n",
    "        # Initalize SSE Dict (LOC) and the SSE sequence (ASG) from STRIDE outfiles.\n",
    "        # Either from the standard folder (base dataset) or from an explicitly stated STRIDE file. (new GAIN)\n",
    "        if explicit_stride_file:\n",
    "            # Read directly from the explicitly stated STRIDE file. (new GAIN)\n",
    "            self.complete_sse_dict = sse_func.read_sse_loc(explicit_stride_file) \n",
    "            self.sse_sequence = sse_func.read_sse_asg(explicit_stride_file)\n",
    "        else:\n",
    "            # Find SSE data in corresponding STRIDE files (base data). Extract corresponding STRIDE files from the list and read SSE from that. (base dataset)\n",
    "            self.complete_sse_dict = sse_func.find_stride_file(self.name.replace(\".fa\",\"\")) # previously: fasta_file.split(\"/\")[-1][:-3]\n",
    "            self.sse_sequence = sse_func.read_sse_asg(self.name.replace(\".fa\",\"\"))\n",
    "        # Try to detect GAIN-like order of SSE. Frist criterion is a C-terminal strand being present (= Stachel/TA)\n",
    "        try: \n",
    "            self.end = self.complete_sse_dict['Strand'][-1][1]\n",
    "            self.isValid = True\n",
    "        except: \n",
    "            print(\"No Strands detected. This is not a GAIN domain.\")\n",
    "            self.isValid = False\n",
    "            return      \n",
    "\n",
    "        # Find the domain boundaries (this includes a check whether the sequence is in fact a GAIN)\n",
    "        # Will return (None, None) if checks fail. \n",
    "        self.start, self.subdomain_boundary = sse_func.find_boundaries(self.complete_sse_dict, \n",
    "                                                                       self.end, \n",
    "                                                                       bracket_size=subdomain_bracket_size, \n",
    "                                                                       domain_threshold=domain_threshold,\n",
    "                                                                       coil_weight=coil_weight)\n",
    "        if (self.start is not None):\n",
    "            self.hasSubdomain = True\n",
    "\n",
    "        if self.start == None:\n",
    "            print(\"No Subdomain boundaries detected. Possible Fragment found.\")\n",
    "            self.hasSubdomain = False\n",
    "            # For possible Fragment detection (i.e. Subdomain B only sequences), set start as the N-terminal res. of the first beta sheet    \n",
    "            self.start = np.amin(np.array(self.complete_sse_dict[\"Strand\"]))\n",
    "        \n",
    "        # Initialize residue indices as list, starting form zero, indexing EXISTING residues including \"X\" etc.\n",
    "        self.index = list(range(0, self.end-self.start+1))\n",
    "        # Initialize one-letter GAIN sequence as list\n",
    "        #print(f\"[DEBUG] gain_classes.GainDomain :\\n\\t{self.start = }\\n\\t{self.end = }\\n\\t{len(sequence) = }\\n\\t{self.end-self.start+1 = }\")\n",
    "        if is_truncated:\n",
    "            # SANITY CHECK: There might occur a case where the GAIN domain is detected anew (i.e. when different parameters are used). There might be a truncation therefore.\n",
    "            #               If that is the case, truncate the sequence N-terminally to that only ((self.end-self.start+1)) residues are included\n",
    "            if len(sequence) > (self.end-self.start+1):\n",
    "                print(f\"[DEBUG] gain_classes.GainDomain : {self.name}\\nDETECTED ALTERED GAIN DOMAIN DETECTION. TRUNCATING @ RESIDUE : {len(sequence)-self.end+self.start}\"\n",
    "                    f\"\\n\\t{self.start = }\\t{self.end = }\\n\\t{len(sequence) = }\\n\\t{self.end-self.start+1 = }\")\n",
    "                self.sequence = np.asarray(list(sequence[len(sequence)-self.end+self.start-1:])) # Begin with the new first residue, end normally\n",
    "                print(f\"[DEBUG]: gain_classes.GainDomain : \\n\\t {len(sequence) = }, {len(self.sequence) = }\\n{sequence}\\n{''.join(self.sequence)}\")\n",
    "\n",
    "            elif len(sequence) < (self.end-self.start+1): \n",
    "                # This is an edge case where the signal detection identifies a Sheet-segment in Subdomain A. Therefore, non-cons. GAIN domain.\n",
    "                print(f\"[DEBUG] gain_classes.GainDomain : {self.name}\\nSEQUENCE LENGTH SHORTER THAN DETECTED GAIN BOUNDARIES.!\\n\"\n",
    "                    f\"IT WILL BE DECLARED INVALID.\\n{len(sequence) =}\\n{self.end+self.start = }\")\n",
    "                self.sse_dict = sse_func.cut_sse_dict(self.start, self.end, self.complete_sse_dict)\n",
    "                print(f\"[DEBUG] gain_classes.GainDomain.__init__():\\n {self.subdomain_boundary = }, {type(self.subdomain_boundary) = }\")\n",
    "                if self.subdomain_boundary is None :\n",
    "                    self.subdomain_boundary = 0\n",
    "                self.plot_helicality(savename=f\"{self.name}_SEQSHORT_SKIP.png\")\n",
    "                self.isValid = False\n",
    "                self.hasSubdomain = False\n",
    "                return\n",
    "\n",
    "            else:\n",
    "                self.sequence = np.asarray(list(sequence))\n",
    "        if sequence and not is_truncated: \n",
    "            self.sequence = np.asarray(list(sequence[self.start:self.end+1]))\n",
    "        if fasta_file and not is_truncated:\n",
    "            self.sequence = np.asarray(list(sse_func.read_seq(fasta_file)))[self.start:self.end+1]\n",
    "        ''' Find the indices of the Alignment where each residue of the sequence is located.\n",
    "            For base dataset, this will be the base dataset alignment,\n",
    "            For new GAIN, this will be the alignment appended by the adding method.\n",
    "            Returns empty list if failed. '''\n",
    "        #print(f\"DEBUG\", self.sequence, type(self.sequence), self.sequence.shape)\n",
    "        #print(f\"DEBUG: Getting alignment indices with: {self.name}, {self.sequence.shape = }, {alignment_file} {type(alignment_dict)}\")\n",
    "        #print(f\"{self.sequence = }\\n{self.start = }\\n{self.end = }\\n{len(self.sequence) = }\")\n",
    "        \n",
    "        if truncation_map is not None: \n",
    "            cut_truncation_map = truncation_map[self.start:self.end+1]\n",
    "        else:\n",
    "            cut_truncation_map = None\n",
    "\n",
    "        # Here the alignment indices get overridden by the input. Since these incorporate the full sequence, truncate between start and end.\n",
    "        self.alignment_indices = alignment_indices[self.start:self.end+1]\n",
    "        print(f\"[DEBUG] {len(self.alignment_indices) = }\")\n",
    "        # Cut down the SSE dictionary down to the GAIN only\n",
    "        self.sse_dict = sse_func.cut_sse_dict(self.start, self.end, self.complete_sse_dict)\n",
    "\n",
    "        # get a name map based on enumerating the SSE segments,\n",
    "        # THIS IS NOT THE ACTUAL NOMENCLATURE BUT A SELF-CONSISTENT METHOD FOR OVERVIEW PURPOSES\n",
    "        self.sse_name_map = None\n",
    "        if not skip_naming:\n",
    "            self.sse_name_map = sse_func.name_sse(self.sse_dict, \n",
    "                                              self.subdomain_boundary, \n",
    "                                              self.start, \n",
    "                                              self.end,\n",
    "                                              self.sse_sequence)\n",
    "        \n",
    "        # Find the GPS residues (triad) based on the alignment column of gps-minus-one (GPS-1 N-terminal residue before cleavage site)\n",
    "        self.GPS = GPS(self.alignment_indices, \n",
    "                       self.sse_dict, \n",
    "                       self.index, \n",
    "                       self.sequence, \n",
    "                       self.start,\n",
    "                       gps_minus_one=gps_index)\n",
    "        \n",
    "        # parse the Quality from the input quality LIST, not the quality file\n",
    "        # The input as a list is deliberate to make the quality parameter more flexible,\n",
    "        # You could input any kind of quality signal here\n",
    "        self.residue_quality = sse_func.get_quality(self.alignment_indices, quality)\n",
    "\n",
    "        if self.hasSubdomain == True:\n",
    "            # enumeration + evaluation of subdomain SSE composition\n",
    "            alpha, beta, a_breaks, b_breaks = sse_func.get_subdomain_sse(self.sse_dict, \n",
    "                                                                         self.subdomain_boundary, \n",
    "                                                                         self.start, \n",
    "                                                                         self.end,\n",
    "                                                                         self.sse_sequence,\n",
    "                                                                         stride_outlier_mode=stride_outlier_mode)\n",
    "            self.sda_helices = np.subtract(alpha, self.start)\n",
    "            #print(f\"[DEBUG] gain_classes.GainDomain : {alpha = } ,{self.sda_helices = }\")\n",
    "            self.sdb_sheets = np.subtract(beta, self.start)\n",
    "            self.a_breaks = a_breaks\n",
    "            self.b_breaks = b_breaks\n",
    "            #print(f\"{a_breaks = }, \\n {self.a_breaks = }\")\n",
    "        # Gather the respective anchors for this GainDomain\n",
    "        if not hasattr(self, 'sda_helices'):\n",
    "            if self.subdomain_boundary is None :\n",
    "                self.subdomain_boundary = 0\n",
    "            self.plot_helicality(savename=f\"{self.name}_NO_HELICES.png\")\n",
    "            print(f\"[ERROR] gain_classes.__init()__ : NO SDA HELICES DETECTED\\n{self.name}\")\n",
    "            self.isValid = False \n",
    "            self.hasSubdomain = False\n",
    "            return\n",
    "        print(\"This Domain has notations for:\\nHelices:\\t\",len(self.sda_helices),\"\\nSheets:\\t\", len(self.sdb_sheets),\"\\nLength:\\t\",len(self.sequence))\n",
    "        print(self.residue_quality[-30:], len(self.residue_quality))\n",
    "        \n",
    "        self.Anchors = PrealignedAnchors(self)\n",
    "\n",
    "class PrealignedAnchors(Anchors):\n",
    "    def __init__(self, a_gain_domain):\n",
    "        sse_names = []\n",
    "        quality_values = []\n",
    "        alignment_indices = []\n",
    "        gain_residues = []\n",
    "        relative_positions = []\n",
    "        # Mush together the smoothened SSE from both subdomains\n",
    "        all_sse = np.concatenate((a_gain_domain.sda_helices, a_gain_domain.sdb_sheets), axis=0)\n",
    "\n",
    "        # print(f\"{a_gain.domain.sdb_sheets = }\")\n",
    "        #print(f\"[DEBUG] gain_classes.Anchors : {a_gain_domain.residue_quality}, \\n {all_sse = } \")\n",
    "\n",
    "        # Get the residue within each SSE of the highest value of the quality metric\n",
    "        for i in range(all_sse.shape[0]):\n",
    "            print(f\"[DEBUG] gain_classes.Anchors :\\n\\t{i = }\\n\\t{all_sse[i,:] = }\\n\\t{a_gain_domain.residue_quality[all_sse[i,0]:all_sse[i,1]] = }\")\n",
    "            best_index = all_sse[i,0] + \\\n",
    "                         np.argmax(a_gain_domain.residue_quality[all_sse[i,0]:all_sse[i,1]])\n",
    "\n",
    "            # For which (self-consistently enumerated) SSE is this\n",
    "            #sse_names.append(a_gain_domain.sse_name_map[best_index])\n",
    "\n",
    "            # What is the associated quality value\n",
    "            quality_values.append(a_gain_domain.residue_quality[best_index])   \n",
    "            # In which alignment column is it\n",
    "            alignment_indices.append(a_gain_domain.alignment_indices[best_index]) \n",
    "            # What is the residue name\n",
    "            gain_residues.append(a_gain_domain.sequence[best_index])\n",
    "            # What is the relative best quality position in the respective SSE\n",
    "            relative_positions.append(best_index)\n",
    "\n",
    "        # Feed into class attributes\n",
    "        self.sse_names = np.array(sse_names)\n",
    "        self.quality_values = np.array(quality_values)\n",
    "        self.alignment_indices = np.array(alignment_indices)\n",
    "        self.gain_residues = np.array(gain_residues)\n",
    "        self.relative_positions = np.array(relative_positions)\n",
    "        self.count = all_sse.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the overridden intializing function for PrealignedGain, create this domain for each invertebrate sequence and create the indexing subsequently, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertebrate_proteins = [f for f in glob.glob(\"/home/hildilab/projects/GPS_massif/invert_truncs/alignme/aln/*\") if \"zip\" not in f]\n",
    "invertebrate_strides = glob.glob(\"/home/hildilab/projects/GPS_massif/invert_truncs/*/best_model.stride\")\n",
    "\n",
    "for xdir in invertebrate_proteins: # This is so far based on directory names.\n",
    "    #xdir = invertebrate_proteins[0]\n",
    "\n",
    "    alnfile = glob.glob(f\"{xdir}/*aln\")[0]\n",
    "    target_seq_file = [f for f in glob.glob(f\"{xdir}/fasta2*\") if \".\" not in f][0]\n",
    "    target_name, target_seq = sse_func.read_seq(target_seq_file, return_name=True)\n",
    "    #print(glob.glob(f\"{xdir}/fasta2*\")[0])\n",
    "    print(target_name, target_seq)\n",
    "    aln_dict = read_pw_alignment(alnfile)\n",
    "    mapper = map_pw_alignment(aln_dict, template_seq=seq, target_seq=target_seq, template_id=\"Q6QNK2\")\n",
    "    # this mapper is zero_indexed.\n",
    "    print(f\"[DEBUG] {len(mapper) = }\")\n",
    "\n",
    "    # Build the target alignment columns from mapping the parwise matrix onto the respective template alignment indices\n",
    "    tar_aln_cols = np.zeros((len(mapper)), dtype=int)\n",
    "    for i,val in enumerate(mapper):\n",
    "        if not math.isnan(val):\n",
    "            tar_aln_cols[i]=d1_gain.alignment_indices[int(val)]\n",
    "    #print(np.unique(tar_aln_cols[~np.isnan(mapper)]))\n",
    "\n",
    "    # Find the corresponding stride file with the identifier\n",
    "    identifier = re.split(r'[-_]', target_name)[0]\n",
    "    print(\"identifier:\", identifier)\n",
    "    target_stride_file = [s for s in invertebrate_strides if identifier in s][0]\n",
    "\n",
    "    gain = PrealignedGain(alignment_file=alignment_file, \n",
    "                    aln_cutoff=aln_cutoff,\n",
    "                    quality=quality,\n",
    "                    gps_index=gps_minus_one, \n",
    "                    alignment_indices=tar_aln_cols,\n",
    "                    name=target_name,\n",
    "                    sequence=target_seq,\n",
    "                    explicit_stride_file=target_stride_file\n",
    "                    )\n",
    "    if gain.isValid:\n",
    "        gain.create_indexing(anchors, anchor_occupation, anchor_dict, outdir=\"/home/hildilab/projects/GPS_massif/invert_truncs/indexing\")\n",
    "    #gain.plot_profile(outdir='/home/hildilab/projects/GPS_massif/invert_truncs/profiles')\n",
    "    #gain.plot_helicality(savename=f'/home/hildilab/projects/GPS_massif/invert_truncs/profiles/{gain.name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_positions = ['H1.50','H1.54','H1.57','H1.61','H2.56','H2.57','H2.60','H2.61','H3.36','H3.43',\n",
    "'H3.44','H3.51','H3.53','H3.56','H4.38','H4.41','H4.51','H5.37','H5.38','H5.42','H5.44',\n",
    "'H5.48','H5.50','H5.59','H6.42','H6.54','H6.56','H7.40','H7.51','H8.46','H8.58','H8.60',\n",
    "'S1.48','S2.47','S2.51','S2.53','S2.58','S3.53','S3.55','S4.56','S5.48','S5.52','S5.55',\n",
    "'S6.50','S7.45','S7.52','S7.57','S9.53','S10.50','S11.54','S11.55','S12.47','S12.50','S12.52','S13.48','S13.50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(invertebrate_proteins)\n",
    "dcirl = '/home/hildilab/projects/GPS_massif/invert_truncs/alignme/aln/e1jh11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad450da4e6f5b8cdd3942a14692e4e36ff09ff1e9c8df5cfaea1622af0db4001"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
